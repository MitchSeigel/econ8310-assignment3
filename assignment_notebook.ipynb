{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8e649671-64ae-4692-a381-33974ffa666a",
      "metadata": {
        "id": "8e649671-64ae-4692-a381-33974ffa666a"
      },
      "source": [
        "# Assignment 3\n",
        "## Econ 8310 - Business Forecasting\n",
        "\n",
        "For homework assignment 3, you will work with [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), a more fancier data set.\n",
        "\n",
        "- You must create a custom data loader as described in the first week of neural network lectures [2 points]\n",
        "    - You will NOT receive credit for this if you use the pytorch prebuilt loader for Fashion MNIST!\n",
        "- You must create a working and trained neural network using only pytorch [2 points]\n",
        "- You must store your weights and create an import script so that I can evaluate your model without training it [2 points]\n",
        "\n",
        "Highest accuracy score gets some extra credit!\n",
        "\n",
        "Submit your forked repository URL on Canvas! :) I'll be manually grading this assignment.\n",
        "\n",
        "Some checks you can make on your own:\n",
        "- Did you manually process the data or use a prebuilt loader (see above)?\n",
        "- Does your script train a neural network on the assigned data?\n",
        "- Did your script save your model?\n",
        "- Do you have separate code to import your model for use after training?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import plotly.express as px\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import urllib.request\n",
        "import gzip\n",
        "import numpy as np\n",
        "import struct\n",
        "\n",
        "# Custom dataloader for the Fashion-MNIST dataset\n",
        "class FashionMNIST(Dataset):\n",
        "    def __init__(self, train_images_url, train_labels_url, test_images_url, test_labels_url):\n",
        "        self.unzip(train_images_url, train_labels_url, test_images_url, test_labels_url)\n",
        "\n",
        "    def unzip(self, train_images_url, train_labels_url, test_images_url, test_labels_url):\n",
        "        with urllib.request.urlopen(train_images_url) as response, gzip.GzipFile(fileobj=response) as f:\n",
        "            magic, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
        "            self.train_images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_images, rows, cols)\n",
        "\n",
        "        with urllib.request.urlopen(train_labels_url) as response, gzip.GzipFile(fileobj=response) as f:\n",
        "            magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
        "            self.train_labels = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_labels)\n",
        "\n",
        "        with urllib.request.urlopen(test_images_url) as response, gzip.GzipFile(fileobj=response) as f:\n",
        "            magic, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
        "            self.test_images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_images, rows, cols)\n",
        "\n",
        "        with urllib.request.urlopen(test_labels_url) as response, gzip.GzipFile(fileobj=response) as f:\n",
        "            magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
        "            self.test_labels = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_labels)\n",
        "        return len(self.test_labels)\n",
        "\n",
        "    def __getitemTrain__(self, idx):\n",
        "        image = torch.tensor(self.train_images[idx], dtype=torch.float32).unsqueeze(0)\n",
        "        label = torch.tensor(self.train_labels[idx], dtype=torch.long)\n",
        "        return image, label\n",
        "\n",
        "    def __getitemTest__(self, idx):\n",
        "        image = torch.tensor(self.test_images[idx], dtype=torch.float32).unsqueeze(0)\n",
        "        label = torch.tensor(self.test_labels[idx], dtype=torch.long)\n",
        "        return image, label\n",
        "\n",
        "# URLs for training\n",
        "train_images_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/b2617bb6d3ffa2e429640350f613e3291e10b141/data/fashion/train-images-idx3-ubyte.gz'\n",
        "train_labels_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/b2617bb6d3ffa2e429640350f613e3291e10b141/data/fashion/train-labels-idx1-ubyte.gz'\n",
        "\n",
        "# URLs for testing\n",
        "test_images_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/b2617bb6d3ffa2e429640350f613e3291e10b141/data/fashion/t10k-images-idx3-ubyte.gz'\n",
        "test_labels_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/b2617bb6d3ffa2e429640350f613e3291e10b141/data/fashion/t10k-labels-idx1-ubyte.gz'\n",
        "\n",
        "# Create an instances for both the training dataset and testing dataset\n",
        "train_dataset = FashionMNIST(train_images_url, train_labels_url, test_images_url, test_labels_url)\n",
        "test_dataset = FashionMNIST(test_images_url, test_labels_url, test_images_url, test_labels_url)\n",
        "\n",
        "# Create the dataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# len(train_dataset)\n",
        "len(test_dataset)\n",
        "\n",
        "# idx=2\n",
        "# print(f\"This image is labeled a {train_dataset.__getitemTrain__(idx)[1]}\")\n",
        "# px.imshow(train_dataset.__getitemTrain__(idx)[0].reshape(28, 28))\n",
        "\n",
        "# idx=2\n",
        "# print(f\"This image is labeled a {train_dataset.__getitemTest__(idx)[1]}\")\n",
        "# px.imshow(test_dataset.__getitemTest__(idx)[0].reshape(28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhhWfz20vHX8",
        "outputId": "272e4722-3b93-4c04-ad44-fd58ee1161eb"
      },
      "id": "NhhWfz20vHX8",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tLRfsUozIuiU"
      },
      "id": "tLRfsUozIuiU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}