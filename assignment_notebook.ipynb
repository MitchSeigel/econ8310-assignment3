{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8e649671-64ae-4692-a381-33974ffa666a",
      "metadata": {
        "id": "8e649671-64ae-4692-a381-33974ffa666a"
      },
      "source": [
        "# Assignment 3\n",
        "## Econ 8310 - Business Forecasting\n",
        "\n",
        "For homework assignment 3, you will work with [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist), a more fancier data set.\n",
        "\n",
        "- You must create a custom data loader as described in the first week of neural network lectures [2 points]\n",
        "    - You will NOT receive credit for this if you use the pytorch prebuilt loader for Fashion MNIST!\n",
        "- You must create a working and trained neural network using only pytorch [2 points]\n",
        "- You must store your weights and create an import script so that I can evaluate your model without training it [2 points]\n",
        "\n",
        "Highest accuracy score gets some extra credit!\n",
        "\n",
        "Submit your forked repository URL on Canvas! :) I'll be manually grading this assignment.\n",
        "\n",
        "Some checks you can make on your own:\n",
        "- Did you manually process the data or use a prebuilt loader (see above)?\n",
        "- Does your script train a neural network on the assigned data?\n",
        "- Did your script save your model?\n",
        "- Do you have separate code to import your model for use after training?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import plotly.express as px\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import urllib.request\n",
        "import gzip\n",
        "import numpy as np\n",
        "import struct\n",
        "\n",
        "# Custom dataloader for the Fashion-MNIST dataset\n",
        "class FashionMNIST(Dataset):\n",
        "    def __init__(self, train_images_url, train_labels_url, test_images_url, test_labels_url, train=True):\n",
        "        self.train = train\n",
        "        self.unzip(train_images_url, train_labels_url, test_images_url, test_labels_url)\n",
        "\n",
        "    # Credit to Google and its AI search assistant as my source for this section on how to unzip and use the .gz files for this custom dataloader\n",
        "    def unzip(self, train_images_url, train_labels_url, test_images_url, test_labels_url):\n",
        "        with urllib.request.urlopen(train_images_url) as response, gzip.GzipFile(fileobj=response) as f:\n",
        "            magic, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
        "            self.train_images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_images, rows, cols)\n",
        "\n",
        "        with urllib.request.urlopen(train_labels_url) as response, gzip.GzipFile(fileobj=response) as f:\n",
        "            magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
        "            self.train_labels = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_labels)\n",
        "\n",
        "        with urllib.request.urlopen(test_images_url) as response, gzip.GzipFile(fileobj=response) as f:\n",
        "            magic, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
        "            self.test_images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_images, rows, cols)\n",
        "\n",
        "        with urllib.request.urlopen(test_labels_url) as response, gzip.GzipFile(fileobj=response) as f:\n",
        "            magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
        "            self.test_labels = np.frombuffer(f.read(), dtype=np.uint8).reshape(num_labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_labels) if self.train else len(self.test_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            image = torch.tensor(self.train_images[idx], dtype=torch.float32).unsqueeze(0)\n",
        "            label = torch.tensor(self.train_labels[idx], dtype=torch.long)\n",
        "        else:\n",
        "            image = torch.tensor(self.test_images[idx], dtype=torch.float32).unsqueeze(0)\n",
        "            label = torch.tensor(self.test_labels[idx], dtype=torch.long)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# URLs for training\n",
        "train_images_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/b2617bb6d3ffa2e429640350f613e3291e10b141/data/fashion/train-images-idx3-ubyte.gz'\n",
        "train_labels_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/b2617bb6d3ffa2e429640350f613e3291e10b141/data/fashion/train-labels-idx1-ubyte.gz'\n",
        "\n",
        "# URLs for testing\n",
        "test_images_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/b2617bb6d3ffa2e429640350f613e3291e10b141/data/fashion/t10k-images-idx3-ubyte.gz'\n",
        "test_labels_url = 'https://github.com/zalandoresearch/fashion-mnist/raw/b2617bb6d3ffa2e429640350f613e3291e10b141/data/fashion/t10k-labels-idx1-ubyte.gz'\n",
        "\n",
        "# Create an instances for both the training dataset and testing dataset\n",
        "train_dataset = FashionMNIST(train_images_url, train_labels_url, test_images_url, test_labels_url, train=True)\n",
        "test_dataset = FashionMNIST(train_images_url, train_labels_url, test_images_url, test_labels_url, train=False)\n",
        "\n",
        "# Create the dataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# len(train_dataset)\n",
        "# len(test_dataset)\n",
        "\n",
        "# idx=2\n",
        "# print(f\"This image is labeled a {train_dataset.__getitemTrain__(idx)[1]}\")\n",
        "# px.imshow(train_dataset.__getitemTrain__(idx)[0].reshape(28, 28))\n",
        "\n",
        "# idx=2\n",
        "# print(f\"This image is labeled a {train_dataset.__getitemTest__(idx)[1]}\")\n",
        "# px.imshow(test_dataset.__getitemTest__(idx)[0].reshape(28, 28))\n",
        "\n",
        "# Linear Neural Network Classifier Model\n",
        "class FashionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(FashionNet, self).__init__()\n",
        "      self.flatten = nn.Flatten()\n",
        "\n",
        "      self.linear_relu_model = nn.Sequential(\n",
        "            nn.LazyLinear(10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.flatten(x)\n",
        "      output = self.linear_relu_model(x)\n",
        "      return output\n",
        "\n",
        "model = FashionNet()\n",
        "\n",
        "# training parameters\n",
        "learning_rate = 1e-2\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "# The loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# The optimizer with the parameters above and learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(),\n",
        "     lr=learning_rate)\n",
        "\n",
        "# training class to train the model\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# testing class to test our trained model\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "# Train the model\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhhWfz20vHX8",
        "outputId": "73f81561-ff36-485e-c01c-6b9aada791d8"
      },
      "id": "NhhWfz20vHX8",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 113.254608  [   64/60000]\n",
            "loss: 5974.152832  [  704/60000]\n",
            "loss: 5123.002930  [ 1344/60000]\n",
            "loss: 4278.317871  [ 1984/60000]\n",
            "loss: 1414.157959  [ 2624/60000]\n",
            "loss: 4019.626709  [ 3264/60000]\n",
            "loss: 3342.874756  [ 3904/60000]\n",
            "loss: 1557.008911  [ 4544/60000]\n",
            "loss: 7298.535156  [ 5184/60000]\n",
            "loss: 722.028320  [ 5824/60000]\n",
            "loss: 835.096802  [ 6464/60000]\n",
            "loss: 4360.522461  [ 7104/60000]\n",
            "loss: 1559.303589  [ 7744/60000]\n",
            "loss: 3567.297119  [ 8384/60000]\n",
            "loss: 2412.413086  [ 9024/60000]\n",
            "loss: 5338.792969  [ 9664/60000]\n",
            "loss: 2216.832031  [10304/60000]\n",
            "loss: 672.798645  [10944/60000]\n",
            "loss: 1046.229004  [11584/60000]\n",
            "loss: 1583.129395  [12224/60000]\n",
            "loss: 857.627075  [12864/60000]\n",
            "loss: 1093.071411  [13504/60000]\n",
            "loss: 1250.139038  [14144/60000]\n",
            "loss: 1771.676270  [14784/60000]\n",
            "loss: 1367.239014  [15424/60000]\n",
            "loss: 1269.380005  [16064/60000]\n",
            "loss: 786.349792  [16704/60000]\n",
            "loss: 1305.623901  [17344/60000]\n",
            "loss: 1633.592529  [17984/60000]\n",
            "loss: 1492.697998  [18624/60000]\n",
            "loss: 1847.348389  [19264/60000]\n",
            "loss: 1790.705933  [19904/60000]\n",
            "loss: 1745.967285  [20544/60000]\n",
            "loss: 454.104523  [21184/60000]\n",
            "loss: 4763.981445  [21824/60000]\n",
            "loss: 1182.310425  [22464/60000]\n",
            "loss: 3778.914795  [23104/60000]\n",
            "loss: 816.816467  [23744/60000]\n",
            "loss: 2762.480225  [24384/60000]\n",
            "loss: 1086.679199  [25024/60000]\n",
            "loss: 3924.501953  [25664/60000]\n",
            "loss: 1813.960083  [26304/60000]\n",
            "loss: 1384.890381  [26944/60000]\n",
            "loss: 1059.097900  [27584/60000]\n",
            "loss: 718.904785  [28224/60000]\n",
            "loss: 3003.582520  [28864/60000]\n",
            "loss: 2581.712402  [29504/60000]\n",
            "loss: 2839.484131  [30144/60000]\n",
            "loss: 1391.649902  [30784/60000]\n",
            "loss: 488.233459  [31424/60000]\n",
            "loss: 1166.052368  [32064/60000]\n",
            "loss: 1128.951294  [32704/60000]\n",
            "loss: 978.059021  [33344/60000]\n",
            "loss: 1417.684082  [33984/60000]\n",
            "loss: 675.721069  [34624/60000]\n",
            "loss: 660.743286  [35264/60000]\n",
            "loss: 953.209412  [35904/60000]\n",
            "loss: 1278.654175  [36544/60000]\n",
            "loss: 2390.069580  [37184/60000]\n",
            "loss: 1011.295349  [37824/60000]\n",
            "loss: 1725.993286  [38464/60000]\n",
            "loss: 1294.472900  [39104/60000]\n",
            "loss: 1470.177246  [39744/60000]\n",
            "loss: 2307.497803  [40384/60000]\n",
            "loss: 1477.907837  [41024/60000]\n",
            "loss: 3170.767578  [41664/60000]\n",
            "loss: 1020.552246  [42304/60000]\n",
            "loss: 5277.432129  [42944/60000]\n",
            "loss: 810.390198  [43584/60000]\n",
            "loss: 2636.737793  [44224/60000]\n",
            "loss: 1474.419434  [44864/60000]\n",
            "loss: 670.358765  [45504/60000]\n",
            "loss: 2855.354004  [46144/60000]\n",
            "loss: 835.539673  [46784/60000]\n",
            "loss: 1330.648926  [47424/60000]\n",
            "loss: 988.769470  [48064/60000]\n",
            "loss: 927.578491  [48704/60000]\n",
            "loss: 1419.249756  [49344/60000]\n",
            "loss: 1538.340820  [49984/60000]\n",
            "loss: 1493.843018  [50624/60000]\n",
            "loss: 2820.247314  [51264/60000]\n",
            "loss: 4321.550781  [51904/60000]\n",
            "loss: 4513.123047  [52544/60000]\n",
            "loss: 2631.546143  [53184/60000]\n",
            "loss: 837.000244  [53824/60000]\n",
            "loss: 2576.098145  [54464/60000]\n",
            "loss: 1052.237793  [55104/60000]\n",
            "loss: 553.758118  [55744/60000]\n",
            "loss: 1763.402222  [56384/60000]\n",
            "loss: 1316.834473  [57024/60000]\n",
            "loss: 1016.799500  [57664/60000]\n",
            "loss: 1395.307739  [58304/60000]\n",
            "loss: 764.829224  [58944/60000]\n",
            "loss: 1922.891846  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 75.6%, Avg loss: 1242.432148 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 910.127136  [   64/60000]\n",
            "loss: 929.065186  [  704/60000]\n",
            "loss: 433.707520  [ 1344/60000]\n",
            "loss: 1206.190918  [ 1984/60000]\n",
            "loss: 1094.588501  [ 2624/60000]\n",
            "loss: 978.867554  [ 3264/60000]\n",
            "loss: 1288.159668  [ 3904/60000]\n",
            "loss: 2095.199219  [ 4544/60000]\n",
            "loss: 1433.749390  [ 5184/60000]\n",
            "loss: 1251.140869  [ 5824/60000]\n",
            "loss: 807.881836  [ 6464/60000]\n",
            "loss: 574.313110  [ 7104/60000]\n",
            "loss: 2795.210449  [ 7744/60000]\n",
            "loss: 1716.994995  [ 8384/60000]\n",
            "loss: 1505.439575  [ 9024/60000]\n",
            "loss: 811.967529  [ 9664/60000]\n",
            "loss: 3033.529541  [10304/60000]\n",
            "loss: 636.232300  [10944/60000]\n",
            "loss: 1031.551636  [11584/60000]\n",
            "loss: 2361.714844  [12224/60000]\n",
            "loss: 4287.666504  [12864/60000]\n",
            "loss: 1242.003662  [13504/60000]\n",
            "loss: 649.274475  [14144/60000]\n",
            "loss: 1012.412537  [14784/60000]\n",
            "loss: 677.595459  [15424/60000]\n",
            "loss: 1676.669434  [16064/60000]\n",
            "loss: 1314.915771  [16704/60000]\n",
            "loss: 1617.704224  [17344/60000]\n",
            "loss: 1492.190918  [17984/60000]\n",
            "loss: 874.765564  [18624/60000]\n",
            "loss: 762.863098  [19264/60000]\n",
            "loss: 1008.447144  [19904/60000]\n",
            "loss: 803.520935  [20544/60000]\n",
            "loss: 532.435852  [21184/60000]\n",
            "loss: 3262.959717  [21824/60000]\n",
            "loss: 922.148560  [22464/60000]\n",
            "loss: 3472.823730  [23104/60000]\n",
            "loss: 1020.438416  [23744/60000]\n",
            "loss: 1423.610840  [24384/60000]\n",
            "loss: 841.493530  [25024/60000]\n",
            "loss: 955.318726  [25664/60000]\n",
            "loss: 2285.225586  [26304/60000]\n",
            "loss: 1230.537598  [26944/60000]\n",
            "loss: 2105.352051  [27584/60000]\n",
            "loss: 926.194641  [28224/60000]\n",
            "loss: 1883.412109  [28864/60000]\n",
            "loss: 1378.232178  [29504/60000]\n",
            "loss: 1858.277100  [30144/60000]\n",
            "loss: 1016.581116  [30784/60000]\n",
            "loss: 1380.181885  [31424/60000]\n",
            "loss: 1109.234741  [32064/60000]\n",
            "loss: 961.983276  [32704/60000]\n",
            "loss: 412.627563  [33344/60000]\n",
            "loss: 2136.311035  [33984/60000]\n",
            "loss: 617.684937  [34624/60000]\n",
            "loss: 545.223450  [35264/60000]\n",
            "loss: 754.363892  [35904/60000]\n",
            "loss: 2796.735840  [36544/60000]\n",
            "loss: 2035.916992  [37184/60000]\n",
            "loss: 761.456848  [37824/60000]\n",
            "loss: 1190.318481  [38464/60000]\n",
            "loss: 1922.784546  [39104/60000]\n",
            "loss: 1632.953369  [39744/60000]\n",
            "loss: 1267.451782  [40384/60000]\n",
            "loss: 1268.858398  [41024/60000]\n",
            "loss: 1279.826904  [41664/60000]\n",
            "loss: 1098.307617  [42304/60000]\n",
            "loss: 1208.009155  [42944/60000]\n",
            "loss: 806.319214  [43584/60000]\n",
            "loss: 1937.948486  [44224/60000]\n",
            "loss: 1388.447632  [44864/60000]\n",
            "loss: 665.669312  [45504/60000]\n",
            "loss: 955.966125  [46144/60000]\n",
            "loss: 1110.277100  [46784/60000]\n",
            "loss: 1185.597168  [47424/60000]\n",
            "loss: 914.159729  [48064/60000]\n",
            "loss: 1479.273315  [48704/60000]\n",
            "loss: 1120.676514  [49344/60000]\n",
            "loss: 1708.718262  [49984/60000]\n",
            "loss: 1210.098999  [50624/60000]\n",
            "loss: 2392.075439  [51264/60000]\n",
            "loss: 2130.713135  [51904/60000]\n",
            "loss: 4551.072754  [52544/60000]\n",
            "loss: 1442.636963  [53184/60000]\n",
            "loss: 778.062012  [53824/60000]\n",
            "loss: 2644.793945  [54464/60000]\n",
            "loss: 996.313904  [55104/60000]\n",
            "loss: 705.930908  [55744/60000]\n",
            "loss: 1203.767822  [56384/60000]\n",
            "loss: 1769.798584  [57024/60000]\n",
            "loss: 1004.286438  [57664/60000]\n",
            "loss: 934.005493  [58304/60000]\n",
            "loss: 755.992126  [58944/60000]\n",
            "loss: 1815.214355  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.3%, Avg loss: 1978.811610 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1331.337891  [   64/60000]\n",
            "loss: 1127.328125  [  704/60000]\n",
            "loss: 480.214142  [ 1344/60000]\n",
            "loss: 1137.461304  [ 1984/60000]\n",
            "loss: 991.296631  [ 2624/60000]\n",
            "loss: 951.598694  [ 3264/60000]\n",
            "loss: 2999.641602  [ 3904/60000]\n",
            "loss: 637.067017  [ 4544/60000]\n",
            "loss: 1263.001221  [ 5184/60000]\n",
            "loss: 1402.186279  [ 5824/60000]\n",
            "loss: 577.361572  [ 6464/60000]\n",
            "loss: 1003.399414  [ 7104/60000]\n",
            "loss: 1532.203979  [ 7744/60000]\n",
            "loss: 839.333252  [ 8384/60000]\n",
            "loss: 1261.951050  [ 9024/60000]\n",
            "loss: 2170.478760  [ 9664/60000]\n",
            "loss: 875.215576  [10304/60000]\n",
            "loss: 763.338440  [10944/60000]\n",
            "loss: 961.326416  [11584/60000]\n",
            "loss: 2091.892822  [12224/60000]\n",
            "loss: 2742.769043  [12864/60000]\n",
            "loss: 1678.564453  [13504/60000]\n",
            "loss: 466.720642  [14144/60000]\n",
            "loss: 2404.511475  [14784/60000]\n",
            "loss: 397.815369  [15424/60000]\n",
            "loss: 1269.577271  [16064/60000]\n",
            "loss: 1019.806580  [16704/60000]\n",
            "loss: 1722.082275  [17344/60000]\n",
            "loss: 1172.338989  [17984/60000]\n",
            "loss: 651.948975  [18624/60000]\n",
            "loss: 1827.746826  [19264/60000]\n",
            "loss: 1733.538574  [19904/60000]\n",
            "loss: 1036.647949  [20544/60000]\n",
            "loss: 543.438232  [21184/60000]\n",
            "loss: 2349.990723  [21824/60000]\n",
            "loss: 501.738831  [22464/60000]\n",
            "loss: 1214.447510  [23104/60000]\n",
            "loss: 1360.731201  [23744/60000]\n",
            "loss: 1630.459106  [24384/60000]\n",
            "loss: 751.019958  [25024/60000]\n",
            "loss: 1570.123657  [25664/60000]\n",
            "loss: 2435.970947  [26304/60000]\n",
            "loss: 1014.987427  [26944/60000]\n",
            "loss: 1965.334473  [27584/60000]\n",
            "loss: 923.150513  [28224/60000]\n",
            "loss: 325.179565  [28864/60000]\n",
            "loss: 1107.251953  [29504/60000]\n",
            "loss: 1508.067871  [30144/60000]\n",
            "loss: 945.068604  [30784/60000]\n",
            "loss: 263.437439  [31424/60000]\n",
            "loss: 1062.677124  [32064/60000]\n",
            "loss: 1437.322388  [32704/60000]\n",
            "loss: 540.122314  [33344/60000]\n",
            "loss: 1726.470459  [33984/60000]\n",
            "loss: 506.817505  [34624/60000]\n",
            "loss: 410.432739  [35264/60000]\n",
            "loss: 615.832520  [35904/60000]\n",
            "loss: 940.580444  [36544/60000]\n",
            "loss: 2693.142578  [37184/60000]\n",
            "loss: 519.376343  [37824/60000]\n",
            "loss: 1308.982422  [38464/60000]\n",
            "loss: 1446.567383  [39104/60000]\n",
            "loss: 1491.606689  [39744/60000]\n",
            "loss: 1193.721313  [40384/60000]\n",
            "loss: 1264.458252  [41024/60000]\n",
            "loss: 1086.404175  [41664/60000]\n",
            "loss: 1066.511719  [42304/60000]\n",
            "loss: 4084.886719  [42944/60000]\n",
            "loss: 1564.365479  [43584/60000]\n",
            "loss: 1328.220215  [44224/60000]\n",
            "loss: 834.274292  [44864/60000]\n",
            "loss: 956.375977  [45504/60000]\n",
            "loss: 841.760559  [46144/60000]\n",
            "loss: 1054.214722  [46784/60000]\n",
            "loss: 1271.193604  [47424/60000]\n",
            "loss: 955.386841  [48064/60000]\n",
            "loss: 871.049377  [48704/60000]\n",
            "loss: 1196.262939  [49344/60000]\n",
            "loss: 1133.893799  [49984/60000]\n",
            "loss: 907.194702  [50624/60000]\n",
            "loss: 1737.163330  [51264/60000]\n",
            "loss: 3336.374512  [51904/60000]\n",
            "loss: 3536.456299  [52544/60000]\n",
            "loss: 2490.625000  [53184/60000]\n",
            "loss: 1041.555908  [53824/60000]\n",
            "loss: 1638.913574  [54464/60000]\n",
            "loss: 1307.506104  [55104/60000]\n",
            "loss: 895.393555  [55744/60000]\n",
            "loss: 1374.122559  [56384/60000]\n",
            "loss: 1364.231445  [57024/60000]\n",
            "loss: 1514.859619  [57664/60000]\n",
            "loss: 841.450928  [58304/60000]\n",
            "loss: 734.252075  [58944/60000]\n",
            "loss: 2505.079590  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.4%, Avg loss: 1753.876902 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1169.043457  [   64/60000]\n",
            "loss: 1265.505615  [  704/60000]\n",
            "loss: 261.927734  [ 1344/60000]\n",
            "loss: 1234.859863  [ 1984/60000]\n",
            "loss: 931.003113  [ 2624/60000]\n",
            "loss: 1436.278076  [ 3264/60000]\n",
            "loss: 1212.401245  [ 3904/60000]\n",
            "loss: 714.202332  [ 4544/60000]\n",
            "loss: 2367.567627  [ 5184/60000]\n",
            "loss: 3857.020264  [ 5824/60000]\n",
            "loss: 522.091125  [ 6464/60000]\n",
            "loss: 873.362305  [ 7104/60000]\n",
            "loss: 1919.580322  [ 7744/60000]\n",
            "loss: 1082.309570  [ 8384/60000]\n",
            "loss: 1778.058350  [ 9024/60000]\n",
            "loss: 2902.533691  [ 9664/60000]\n",
            "loss: 1657.728882  [10304/60000]\n",
            "loss: 849.717346  [10944/60000]\n",
            "loss: 1163.640625  [11584/60000]\n",
            "loss: 4609.126953  [12224/60000]\n",
            "loss: 1162.459717  [12864/60000]\n",
            "loss: 692.527100  [13504/60000]\n",
            "loss: 890.131836  [14144/60000]\n",
            "loss: 833.830933  [14784/60000]\n",
            "loss: 759.905151  [15424/60000]\n",
            "loss: 818.301453  [16064/60000]\n",
            "loss: 733.221497  [16704/60000]\n",
            "loss: 1413.950928  [17344/60000]\n",
            "loss: 1616.052734  [17984/60000]\n",
            "loss: 552.568359  [18624/60000]\n",
            "loss: 1260.108765  [19264/60000]\n",
            "loss: 951.756226  [19904/60000]\n",
            "loss: 492.820374  [20544/60000]\n",
            "loss: 694.793823  [21184/60000]\n",
            "loss: 2880.155029  [21824/60000]\n",
            "loss: 992.761169  [22464/60000]\n",
            "loss: 2052.822754  [23104/60000]\n",
            "loss: 698.823669  [23744/60000]\n",
            "loss: 1155.447266  [24384/60000]\n",
            "loss: 739.509888  [25024/60000]\n",
            "loss: 1421.734985  [25664/60000]\n",
            "loss: 2800.918945  [26304/60000]\n",
            "loss: 1106.395874  [26944/60000]\n",
            "loss: 2128.290283  [27584/60000]\n",
            "loss: 557.261047  [28224/60000]\n",
            "loss: 677.143921  [28864/60000]\n",
            "loss: 1149.342163  [29504/60000]\n",
            "loss: 1768.432739  [30144/60000]\n",
            "loss: 1261.556519  [30784/60000]\n",
            "loss: 448.606079  [31424/60000]\n",
            "loss: 1503.672729  [32064/60000]\n",
            "loss: 1228.624634  [32704/60000]\n",
            "loss: 422.781586  [33344/60000]\n",
            "loss: 2035.183350  [33984/60000]\n",
            "loss: 346.170685  [34624/60000]\n",
            "loss: 512.376526  [35264/60000]\n",
            "loss: 458.287231  [35904/60000]\n",
            "loss: 1822.184570  [36544/60000]\n",
            "loss: 3152.919922  [37184/60000]\n",
            "loss: 625.912231  [37824/60000]\n",
            "loss: 1150.131348  [38464/60000]\n",
            "loss: 1338.998047  [39104/60000]\n",
            "loss: 1874.868652  [39744/60000]\n",
            "loss: 1322.645508  [40384/60000]\n",
            "loss: 2060.601807  [41024/60000]\n",
            "loss: 2011.710815  [41664/60000]\n",
            "loss: 1202.854370  [42304/60000]\n",
            "loss: 1804.924072  [42944/60000]\n",
            "loss: 3173.258789  [43584/60000]\n",
            "loss: 1629.689087  [44224/60000]\n",
            "loss: 1149.256104  [44864/60000]\n",
            "loss: 998.868164  [45504/60000]\n",
            "loss: 805.861694  [46144/60000]\n",
            "loss: 1218.761841  [46784/60000]\n",
            "loss: 1088.161865  [47424/60000]\n",
            "loss: 1107.522583  [48064/60000]\n",
            "loss: 799.184204  [48704/60000]\n",
            "loss: 1056.097656  [49344/60000]\n",
            "loss: 1131.115723  [49984/60000]\n",
            "loss: 1018.807922  [50624/60000]\n",
            "loss: 2491.285156  [51264/60000]\n",
            "loss: 3608.114746  [51904/60000]\n",
            "loss: 2142.092773  [52544/60000]\n",
            "loss: 735.188721  [53184/60000]\n",
            "loss: 1358.388672  [53824/60000]\n",
            "loss: 643.958679  [54464/60000]\n",
            "loss: 828.773376  [55104/60000]\n",
            "loss: 672.042114  [55744/60000]\n",
            "loss: 891.078674  [56384/60000]\n",
            "loss: 868.988831  [57024/60000]\n",
            "loss: 1095.922974  [57664/60000]\n",
            "loss: 637.588501  [58304/60000]\n",
            "loss: 777.855225  [58944/60000]\n",
            "loss: 4436.548828  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.9%, Avg loss: 3230.950151 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2631.627441  [   64/60000]\n",
            "loss: 652.681213  [  704/60000]\n",
            "loss: 416.785400  [ 1344/60000]\n",
            "loss: 1552.345337  [ 1984/60000]\n",
            "loss: 1291.734497  [ 2624/60000]\n",
            "loss: 1008.277527  [ 3264/60000]\n",
            "loss: 1204.102051  [ 3904/60000]\n",
            "loss: 851.604004  [ 4544/60000]\n",
            "loss: 1952.319214  [ 5184/60000]\n",
            "loss: 973.807007  [ 5824/60000]\n",
            "loss: 286.201935  [ 6464/60000]\n",
            "loss: 900.156982  [ 7104/60000]\n",
            "loss: 2836.858398  [ 7744/60000]\n",
            "loss: 939.260620  [ 8384/60000]\n",
            "loss: 749.033203  [ 9024/60000]\n",
            "loss: 1118.823242  [ 9664/60000]\n",
            "loss: 732.603882  [10304/60000]\n",
            "loss: 2464.617188  [10944/60000]\n",
            "loss: 1233.899536  [11584/60000]\n",
            "loss: 1763.098267  [12224/60000]\n",
            "loss: 765.783875  [12864/60000]\n",
            "loss: 1613.272949  [13504/60000]\n",
            "loss: 502.218475  [14144/60000]\n",
            "loss: 930.170349  [14784/60000]\n",
            "loss: 377.602875  [15424/60000]\n",
            "loss: 841.342407  [16064/60000]\n",
            "loss: 1423.656738  [16704/60000]\n",
            "loss: 1418.290405  [17344/60000]\n",
            "loss: 1601.899292  [17984/60000]\n",
            "loss: 542.799194  [18624/60000]\n",
            "loss: 1043.002930  [19264/60000]\n",
            "loss: 1396.364014  [19904/60000]\n",
            "loss: 1083.583008  [20544/60000]\n",
            "loss: 828.590027  [21184/60000]\n",
            "loss: 3181.691162  [21824/60000]\n",
            "loss: 892.909668  [22464/60000]\n",
            "loss: 1434.733154  [23104/60000]\n",
            "loss: 954.588257  [23744/60000]\n",
            "loss: 1388.145142  [24384/60000]\n",
            "loss: 799.288391  [25024/60000]\n",
            "loss: 2027.172363  [25664/60000]\n",
            "loss: 1857.285156  [26304/60000]\n",
            "loss: 1056.307373  [26944/60000]\n",
            "loss: 1631.518555  [27584/60000]\n",
            "loss: 477.147552  [28224/60000]\n",
            "loss: 320.511475  [28864/60000]\n",
            "loss: 1606.313721  [29504/60000]\n",
            "loss: 2644.043701  [30144/60000]\n",
            "loss: 724.694092  [30784/60000]\n",
            "loss: 275.788940  [31424/60000]\n",
            "loss: 1814.214600  [32064/60000]\n",
            "loss: 793.426636  [32704/60000]\n",
            "loss: 920.000732  [33344/60000]\n",
            "loss: 1783.911377  [33984/60000]\n",
            "loss: 498.117035  [34624/60000]\n",
            "loss: 523.448059  [35264/60000]\n",
            "loss: 815.602295  [35904/60000]\n",
            "loss: 931.913635  [36544/60000]\n",
            "loss: 2103.014404  [37184/60000]\n",
            "loss: 728.606445  [37824/60000]\n",
            "loss: 1200.255127  [38464/60000]\n",
            "loss: 786.835693  [39104/60000]\n",
            "loss: 1323.312866  [39744/60000]\n",
            "loss: 1613.124023  [40384/60000]\n",
            "loss: 1508.429810  [41024/60000]\n",
            "loss: 933.533997  [41664/60000]\n",
            "loss: 1689.567871  [42304/60000]\n",
            "loss: 503.170197  [42944/60000]\n",
            "loss: 1167.308594  [43584/60000]\n",
            "loss: 2553.232910  [44224/60000]\n",
            "loss: 780.448120  [44864/60000]\n",
            "loss: 1352.544800  [45504/60000]\n",
            "loss: 761.343506  [46144/60000]\n",
            "loss: 836.041138  [46784/60000]\n",
            "loss: 600.933044  [47424/60000]\n",
            "loss: 994.778809  [48064/60000]\n",
            "loss: 661.441345  [48704/60000]\n",
            "loss: 886.923950  [49344/60000]\n",
            "loss: 1146.203247  [49984/60000]\n",
            "loss: 685.939819  [50624/60000]\n",
            "loss: 1228.392212  [51264/60000]\n",
            "loss: 4237.406738  [51904/60000]\n",
            "loss: 4200.363770  [52544/60000]\n",
            "loss: 1904.651367  [53184/60000]\n",
            "loss: 1229.520264  [53824/60000]\n",
            "loss: 913.737000  [54464/60000]\n",
            "loss: 1088.879761  [55104/60000]\n",
            "loss: 1010.820923  [55744/60000]\n",
            "loss: 788.968994  [56384/60000]\n",
            "loss: 1160.230957  [57024/60000]\n",
            "loss: 1348.126465  [57664/60000]\n",
            "loss: 694.986877  [58304/60000]\n",
            "loss: 549.374084  [58944/60000]\n",
            "loss: 1874.591431  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.0%, Avg loss: 2521.247259 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1928.068115  [   64/60000]\n",
            "loss: 820.496216  [  704/60000]\n",
            "loss: 678.191895  [ 1344/60000]\n",
            "loss: 757.062256  [ 1984/60000]\n",
            "loss: 1005.176941  [ 2624/60000]\n",
            "loss: 1213.227173  [ 3264/60000]\n",
            "loss: 1433.469238  [ 3904/60000]\n",
            "loss: 550.062866  [ 4544/60000]\n",
            "loss: 1798.875732  [ 5184/60000]\n",
            "loss: 637.443237  [ 5824/60000]\n",
            "loss: 545.557129  [ 6464/60000]\n",
            "loss: 1079.779663  [ 7104/60000]\n",
            "loss: 1270.192505  [ 7744/60000]\n",
            "loss: 1421.763062  [ 8384/60000]\n",
            "loss: 988.775757  [ 9024/60000]\n",
            "loss: 1571.800171  [ 9664/60000]\n",
            "loss: 1092.642456  [10304/60000]\n",
            "loss: 716.084595  [10944/60000]\n",
            "loss: 808.015259  [11584/60000]\n",
            "loss: 3136.032227  [12224/60000]\n",
            "loss: 1126.375854  [12864/60000]\n",
            "loss: 2612.800293  [13504/60000]\n",
            "loss: 417.738617  [14144/60000]\n",
            "loss: 1232.642700  [14784/60000]\n",
            "loss: 493.401489  [15424/60000]\n",
            "loss: 1001.820618  [16064/60000]\n",
            "loss: 963.224182  [16704/60000]\n",
            "loss: 1372.220947  [17344/60000]\n",
            "loss: 1555.540771  [17984/60000]\n",
            "loss: 776.560181  [18624/60000]\n",
            "loss: 1850.570068  [19264/60000]\n",
            "loss: 1342.927734  [19904/60000]\n",
            "loss: 555.065552  [20544/60000]\n",
            "loss: 963.937500  [21184/60000]\n",
            "loss: 2863.071045  [21824/60000]\n",
            "loss: 843.180542  [22464/60000]\n",
            "loss: 2422.020264  [23104/60000]\n",
            "loss: 825.391663  [23744/60000]\n",
            "loss: 2310.432861  [24384/60000]\n",
            "loss: 856.322144  [25024/60000]\n",
            "loss: 801.975647  [25664/60000]\n",
            "loss: 1970.075195  [26304/60000]\n",
            "loss: 1142.417725  [26944/60000]\n",
            "loss: 2349.711182  [27584/60000]\n",
            "loss: 754.097595  [28224/60000]\n",
            "loss: 416.982422  [28864/60000]\n",
            "loss: 1375.685059  [29504/60000]\n",
            "loss: 1187.525391  [30144/60000]\n",
            "loss: 791.237305  [30784/60000]\n",
            "loss: 529.779541  [31424/60000]\n",
            "loss: 802.025208  [32064/60000]\n",
            "loss: 1006.612488  [32704/60000]\n",
            "loss: 346.916656  [33344/60000]\n",
            "loss: 1888.973145  [33984/60000]\n",
            "loss: 411.370911  [34624/60000]\n",
            "loss: 340.814453  [35264/60000]\n",
            "loss: 1065.267822  [35904/60000]\n",
            "loss: 1007.175903  [36544/60000]\n",
            "loss: 2340.761230  [37184/60000]\n",
            "loss: 588.129150  [37824/60000]\n",
            "loss: 1041.815308  [38464/60000]\n",
            "loss: 1379.849976  [39104/60000]\n",
            "loss: 1684.562256  [39744/60000]\n",
            "loss: 1991.287598  [40384/60000]\n",
            "loss: 2108.052246  [41024/60000]\n",
            "loss: 993.392090  [41664/60000]\n",
            "loss: 1900.451050  [42304/60000]\n",
            "loss: 1948.575928  [42944/60000]\n",
            "loss: 2738.372070  [43584/60000]\n",
            "loss: 602.938904  [44224/60000]\n",
            "loss: 1275.392090  [44864/60000]\n",
            "loss: 759.242432  [45504/60000]\n",
            "loss: 774.889282  [46144/60000]\n",
            "loss: 1182.100342  [46784/60000]\n",
            "loss: 1395.559937  [47424/60000]\n",
            "loss: 1255.518677  [48064/60000]\n",
            "loss: 1012.940186  [48704/60000]\n",
            "loss: 1235.241089  [49344/60000]\n",
            "loss: 1788.997437  [49984/60000]\n",
            "loss: 654.192505  [50624/60000]\n",
            "loss: 1426.507568  [51264/60000]\n",
            "loss: 2477.189941  [51904/60000]\n",
            "loss: 3611.048828  [52544/60000]\n",
            "loss: 1305.864502  [53184/60000]\n",
            "loss: 865.369202  [53824/60000]\n",
            "loss: 1004.407959  [54464/60000]\n",
            "loss: 592.837646  [55104/60000]\n",
            "loss: 784.326355  [55744/60000]\n",
            "loss: 1560.476074  [56384/60000]\n",
            "loss: 769.847046  [57024/60000]\n",
            "loss: 1307.288086  [57664/60000]\n",
            "loss: 760.762390  [58304/60000]\n",
            "loss: 718.062378  [58944/60000]\n",
            "loss: 2081.363037  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.5%, Avg loss: 2697.967808 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 2057.214600  [   64/60000]\n",
            "loss: 1421.675293  [  704/60000]\n",
            "loss: 410.608276  [ 1344/60000]\n",
            "loss: 993.503540  [ 1984/60000]\n",
            "loss: 1102.212402  [ 2624/60000]\n",
            "loss: 860.587524  [ 3264/60000]\n",
            "loss: 1294.462646  [ 3904/60000]\n",
            "loss: 691.310913  [ 4544/60000]\n",
            "loss: 1927.001099  [ 5184/60000]\n",
            "loss: 880.154846  [ 5824/60000]\n",
            "loss: 686.279480  [ 6464/60000]\n",
            "loss: 841.938049  [ 7104/60000]\n",
            "loss: 3146.272949  [ 7744/60000]\n",
            "loss: 761.652710  [ 8384/60000]\n",
            "loss: 895.708740  [ 9024/60000]\n",
            "loss: 539.145081  [ 9664/60000]\n",
            "loss: 1583.018799  [10304/60000]\n",
            "loss: 630.698608  [10944/60000]\n",
            "loss: 988.418091  [11584/60000]\n",
            "loss: 1922.189941  [12224/60000]\n",
            "loss: 529.468994  [12864/60000]\n",
            "loss: 1598.602783  [13504/60000]\n",
            "loss: 442.899261  [14144/60000]\n",
            "loss: 1090.376465  [14784/60000]\n",
            "loss: 244.678421  [15424/60000]\n",
            "loss: 1029.523315  [16064/60000]\n",
            "loss: 1040.674438  [16704/60000]\n",
            "loss: 1372.761963  [17344/60000]\n",
            "loss: 1012.988098  [17984/60000]\n",
            "loss: 892.473450  [18624/60000]\n",
            "loss: 1273.568848  [19264/60000]\n",
            "loss: 858.784607  [19904/60000]\n",
            "loss: 499.135651  [20544/60000]\n",
            "loss: 751.530212  [21184/60000]\n",
            "loss: 2338.765625  [21824/60000]\n",
            "loss: 1589.782837  [22464/60000]\n",
            "loss: 1191.039795  [23104/60000]\n",
            "loss: 971.846558  [23744/60000]\n",
            "loss: 1200.730957  [24384/60000]\n",
            "loss: 819.390747  [25024/60000]\n",
            "loss: 794.970947  [25664/60000]\n",
            "loss: 2162.718262  [26304/60000]\n",
            "loss: 1026.243164  [26944/60000]\n",
            "loss: 830.377502  [27584/60000]\n",
            "loss: 523.713501  [28224/60000]\n",
            "loss: 342.495178  [28864/60000]\n",
            "loss: 1823.945801  [29504/60000]\n",
            "loss: 1299.332520  [30144/60000]\n",
            "loss: 978.696228  [30784/60000]\n",
            "loss: 896.468323  [31424/60000]\n",
            "loss: 1901.629272  [32064/60000]\n",
            "loss: 976.396790  [32704/60000]\n",
            "loss: 597.153992  [33344/60000]\n",
            "loss: 1218.248413  [33984/60000]\n",
            "loss: 597.491455  [34624/60000]\n",
            "loss: 439.094452  [35264/60000]\n",
            "loss: 1218.609131  [35904/60000]\n",
            "loss: 1097.614502  [36544/60000]\n",
            "loss: 931.843140  [37184/60000]\n",
            "loss: 578.651550  [37824/60000]\n",
            "loss: 1661.586670  [38464/60000]\n",
            "loss: 1225.949951  [39104/60000]\n",
            "loss: 1859.087158  [39744/60000]\n",
            "loss: 1774.313477  [40384/60000]\n",
            "loss: 1379.404053  [41024/60000]\n",
            "loss: 1261.800781  [41664/60000]\n",
            "loss: 1513.800171  [42304/60000]\n",
            "loss: 3776.230957  [42944/60000]\n",
            "loss: 1557.102539  [43584/60000]\n",
            "loss: 2275.966064  [44224/60000]\n",
            "loss: 794.904846  [44864/60000]\n",
            "loss: 1165.222412  [45504/60000]\n",
            "loss: 760.611816  [46144/60000]\n",
            "loss: 1000.075989  [46784/60000]\n",
            "loss: 938.370972  [47424/60000]\n",
            "loss: 1211.207153  [48064/60000]\n",
            "loss: 674.065613  [48704/60000]\n",
            "loss: 1326.925903  [49344/60000]\n",
            "loss: 1070.506592  [49984/60000]\n",
            "loss: 794.207581  [50624/60000]\n",
            "loss: 2242.028809  [51264/60000]\n",
            "loss: 1358.731689  [51904/60000]\n",
            "loss: 3813.208984  [52544/60000]\n",
            "loss: 720.215393  [53184/60000]\n",
            "loss: 548.998840  [53824/60000]\n",
            "loss: 2405.994873  [54464/60000]\n",
            "loss: 897.305298  [55104/60000]\n",
            "loss: 543.560059  [55744/60000]\n",
            "loss: 785.159668  [56384/60000]\n",
            "loss: 879.345764  [57024/60000]\n",
            "loss: 1138.486328  [57664/60000]\n",
            "loss: 367.003967  [58304/60000]\n",
            "loss: 617.448730  [58944/60000]\n",
            "loss: 3650.573730  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.0%, Avg loss: 2270.269999 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1725.058105  [   64/60000]\n",
            "loss: 953.111450  [  704/60000]\n",
            "loss: 413.437317  [ 1344/60000]\n",
            "loss: 895.585815  [ 1984/60000]\n",
            "loss: 1150.466553  [ 2624/60000]\n",
            "loss: 1000.441101  [ 3264/60000]\n",
            "loss: 1279.102295  [ 3904/60000]\n",
            "loss: 615.638855  [ 4544/60000]\n",
            "loss: 1833.485596  [ 5184/60000]\n",
            "loss: 1916.796875  [ 5824/60000]\n",
            "loss: 499.908600  [ 6464/60000]\n",
            "loss: 2239.086670  [ 7104/60000]\n",
            "loss: 653.183350  [ 7744/60000]\n",
            "loss: 3158.431152  [ 8384/60000]\n",
            "loss: 1055.334717  [ 9024/60000]\n",
            "loss: 2192.983643  [ 9664/60000]\n",
            "loss: 676.957214  [10304/60000]\n",
            "loss: 374.460632  [10944/60000]\n",
            "loss: 1184.938843  [11584/60000]\n",
            "loss: 2343.413818  [12224/60000]\n",
            "loss: 1407.525757  [12864/60000]\n",
            "loss: 1863.573120  [13504/60000]\n",
            "loss: 666.753601  [14144/60000]\n",
            "loss: 840.039551  [14784/60000]\n",
            "loss: 442.240387  [15424/60000]\n",
            "loss: 1384.976318  [16064/60000]\n",
            "loss: 1327.205811  [16704/60000]\n",
            "loss: 1551.552979  [17344/60000]\n",
            "loss: 900.857361  [17984/60000]\n",
            "loss: 638.076721  [18624/60000]\n",
            "loss: 1721.862793  [19264/60000]\n",
            "loss: 1448.233521  [19904/60000]\n",
            "loss: 901.877563  [20544/60000]\n",
            "loss: 829.972778  [21184/60000]\n",
            "loss: 2412.322754  [21824/60000]\n",
            "loss: 689.747559  [22464/60000]\n",
            "loss: 2087.819824  [23104/60000]\n",
            "loss: 721.222107  [23744/60000]\n",
            "loss: 2081.750977  [24384/60000]\n",
            "loss: 792.130371  [25024/60000]\n",
            "loss: 1179.080200  [25664/60000]\n",
            "loss: 2111.392822  [26304/60000]\n",
            "loss: 916.901733  [26944/60000]\n",
            "loss: 1509.523804  [27584/60000]\n",
            "loss: 1501.827637  [28224/60000]\n",
            "loss: 1323.200317  [28864/60000]\n",
            "loss: 1282.428467  [29504/60000]\n",
            "loss: 1292.708984  [30144/60000]\n",
            "loss: 675.029297  [30784/60000]\n",
            "loss: 557.877197  [31424/60000]\n",
            "loss: 963.588989  [32064/60000]\n",
            "loss: 1422.328735  [32704/60000]\n",
            "loss: 573.929565  [33344/60000]\n",
            "loss: 1906.763794  [33984/60000]\n",
            "loss: 467.531189  [34624/60000]\n",
            "loss: 328.781250  [35264/60000]\n",
            "loss: 813.960632  [35904/60000]\n",
            "loss: 915.159729  [36544/60000]\n",
            "loss: 2940.151855  [37184/60000]\n",
            "loss: 967.022095  [37824/60000]\n",
            "loss: 1598.023438  [38464/60000]\n",
            "loss: 920.034424  [39104/60000]\n",
            "loss: 955.470276  [39744/60000]\n",
            "loss: 2179.306641  [40384/60000]\n",
            "loss: 1224.295776  [41024/60000]\n",
            "loss: 1407.013428  [41664/60000]\n",
            "loss: 1636.498169  [42304/60000]\n",
            "loss: 792.303101  [42944/60000]\n",
            "loss: 465.596497  [43584/60000]\n",
            "loss: 2233.939453  [44224/60000]\n",
            "loss: 1358.272583  [44864/60000]\n",
            "loss: 688.967651  [45504/60000]\n",
            "loss: 631.580688  [46144/60000]\n",
            "loss: 1263.384888  [46784/60000]\n",
            "loss: 752.411743  [47424/60000]\n",
            "loss: 1111.174072  [48064/60000]\n",
            "loss: 951.999084  [48704/60000]\n",
            "loss: 682.483582  [49344/60000]\n",
            "loss: 1259.315674  [49984/60000]\n",
            "loss: 670.706787  [50624/60000]\n",
            "loss: 1370.264893  [51264/60000]\n",
            "loss: 3442.865723  [51904/60000]\n",
            "loss: 1883.858643  [52544/60000]\n",
            "loss: 2663.612061  [53184/60000]\n",
            "loss: 1112.319336  [53824/60000]\n",
            "loss: 768.530273  [54464/60000]\n",
            "loss: 358.272034  [55104/60000]\n",
            "loss: 699.771118  [55744/60000]\n",
            "loss: 607.260376  [56384/60000]\n",
            "loss: 860.748352  [57024/60000]\n",
            "loss: 1534.156738  [57664/60000]\n",
            "loss: 615.934448  [58304/60000]\n",
            "loss: 743.799927  [58944/60000]\n",
            "loss: 2200.832764  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.5%, Avg loss: 2886.363948 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 2565.549316  [   64/60000]\n",
            "loss: 599.802063  [  704/60000]\n",
            "loss: 424.619080  [ 1344/60000]\n",
            "loss: 978.834229  [ 1984/60000]\n",
            "loss: 1073.540527  [ 2624/60000]\n",
            "loss: 1152.750854  [ 3264/60000]\n",
            "loss: 1248.712158  [ 3904/60000]\n",
            "loss: 530.144897  [ 4544/60000]\n",
            "loss: 3062.071045  [ 5184/60000]\n",
            "loss: 365.613892  [ 5824/60000]\n",
            "loss: 592.760559  [ 6464/60000]\n",
            "loss: 1069.569336  [ 7104/60000]\n",
            "loss: 2299.315918  [ 7744/60000]\n",
            "loss: 1033.809570  [ 8384/60000]\n",
            "loss: 859.028809  [ 9024/60000]\n",
            "loss: 1534.789307  [ 9664/60000]\n",
            "loss: 564.032166  [10304/60000]\n",
            "loss: 2286.789062  [10944/60000]\n",
            "loss: 1084.996094  [11584/60000]\n",
            "loss: 2401.665527  [12224/60000]\n",
            "loss: 3776.006104  [12864/60000]\n",
            "loss: 2133.740479  [13504/60000]\n",
            "loss: 1974.249512  [14144/60000]\n",
            "loss: 2261.422119  [14784/60000]\n",
            "loss: 203.772614  [15424/60000]\n",
            "loss: 1896.753906  [16064/60000]\n",
            "loss: 1283.466553  [16704/60000]\n",
            "loss: 1475.182861  [17344/60000]\n",
            "loss: 1731.602905  [17984/60000]\n",
            "loss: 1084.114990  [18624/60000]\n",
            "loss: 1530.604614  [19264/60000]\n",
            "loss: 1239.895508  [19904/60000]\n",
            "loss: 463.649353  [20544/60000]\n",
            "loss: 907.132568  [21184/60000]\n",
            "loss: 2609.226562  [21824/60000]\n",
            "loss: 477.293091  [22464/60000]\n",
            "loss: 2871.134277  [23104/60000]\n",
            "loss: 817.436035  [23744/60000]\n",
            "loss: 2026.612549  [24384/60000]\n",
            "loss: 691.439087  [25024/60000]\n",
            "loss: 1135.278687  [25664/60000]\n",
            "loss: 1934.866577  [26304/60000]\n",
            "loss: 1106.120361  [26944/60000]\n",
            "loss: 1568.231567  [27584/60000]\n",
            "loss: 599.850586  [28224/60000]\n",
            "loss: 1354.568481  [28864/60000]\n",
            "loss: 1214.036865  [29504/60000]\n",
            "loss: 2063.321289  [30144/60000]\n",
            "loss: 752.645874  [30784/60000]\n",
            "loss: 347.374207  [31424/60000]\n",
            "loss: 1309.070557  [32064/60000]\n",
            "loss: 1413.132812  [32704/60000]\n",
            "loss: 359.176514  [33344/60000]\n",
            "loss: 2575.345947  [33984/60000]\n",
            "loss: 537.557129  [34624/60000]\n",
            "loss: 413.934601  [35264/60000]\n",
            "loss: 1162.712524  [35904/60000]\n",
            "loss: 805.333679  [36544/60000]\n",
            "loss: 2938.474365  [37184/60000]\n",
            "loss: 502.670563  [37824/60000]\n",
            "loss: 746.544617  [38464/60000]\n",
            "loss: 986.573853  [39104/60000]\n",
            "loss: 1204.899048  [39744/60000]\n",
            "loss: 3080.606445  [40384/60000]\n",
            "loss: 638.989746  [41024/60000]\n",
            "loss: 1284.723877  [41664/60000]\n",
            "loss: 1476.088257  [42304/60000]\n",
            "loss: 650.043518  [42944/60000]\n",
            "loss: 533.366882  [43584/60000]\n",
            "loss: 1565.779785  [44224/60000]\n",
            "loss: 808.452209  [44864/60000]\n",
            "loss: 930.391357  [45504/60000]\n",
            "loss: 736.829956  [46144/60000]\n",
            "loss: 1557.166870  [46784/60000]\n",
            "loss: 715.893982  [47424/60000]\n",
            "loss: 1222.895508  [48064/60000]\n",
            "loss: 982.588989  [48704/60000]\n",
            "loss: 629.532288  [49344/60000]\n",
            "loss: 1646.608887  [49984/60000]\n",
            "loss: 658.783264  [50624/60000]\n",
            "loss: 1360.216797  [51264/60000]\n",
            "loss: 3819.053711  [51904/60000]\n",
            "loss: 993.188354  [52544/60000]\n",
            "loss: 1384.238525  [53184/60000]\n",
            "loss: 545.827820  [53824/60000]\n",
            "loss: 943.195557  [54464/60000]\n",
            "loss: 760.590820  [55104/60000]\n",
            "loss: 778.194397  [55744/60000]\n",
            "loss: 514.818359  [56384/60000]\n",
            "loss: 1050.812988  [57024/60000]\n",
            "loss: 904.805237  [57664/60000]\n",
            "loss: 648.525391  [58304/60000]\n",
            "loss: 702.661194  [58944/60000]\n",
            "loss: 1915.741455  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 72.5%, Avg loss: 1563.755232 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1064.722656  [   64/60000]\n",
            "loss: 743.442871  [  704/60000]\n",
            "loss: 1378.799072  [ 1344/60000]\n",
            "loss: 557.132568  [ 1984/60000]\n",
            "loss: 1003.035034  [ 2624/60000]\n",
            "loss: 963.729675  [ 3264/60000]\n",
            "loss: 1200.324219  [ 3904/60000]\n",
            "loss: 779.321350  [ 4544/60000]\n",
            "loss: 1081.401855  [ 5184/60000]\n",
            "loss: 435.081299  [ 5824/60000]\n",
            "loss: 780.842651  [ 6464/60000]\n",
            "loss: 1047.493530  [ 7104/60000]\n",
            "loss: 2826.896729  [ 7744/60000]\n",
            "loss: 1115.702637  [ 8384/60000]\n",
            "loss: 1336.052368  [ 9024/60000]\n",
            "loss: 2543.488770  [ 9664/60000]\n",
            "loss: 1361.333984  [10304/60000]\n",
            "loss: 413.635986  [10944/60000]\n",
            "loss: 1357.993530  [11584/60000]\n",
            "loss: 3437.344482  [12224/60000]\n",
            "loss: 1004.556030  [12864/60000]\n",
            "loss: 1353.017212  [13504/60000]\n",
            "loss: 364.238708  [14144/60000]\n",
            "loss: 1439.234131  [14784/60000]\n",
            "loss: 244.060913  [15424/60000]\n",
            "loss: 804.193481  [16064/60000]\n",
            "loss: 685.969238  [16704/60000]\n",
            "loss: 1425.479004  [17344/60000]\n",
            "loss: 986.131409  [17984/60000]\n",
            "loss: 610.970825  [18624/60000]\n",
            "loss: 1516.022827  [19264/60000]\n",
            "loss: 1875.520264  [19904/60000]\n",
            "loss: 513.934570  [20544/60000]\n",
            "loss: 1060.406982  [21184/60000]\n",
            "loss: 3881.369873  [21824/60000]\n",
            "loss: 3209.541992  [22464/60000]\n",
            "loss: 3126.809570  [23104/60000]\n",
            "loss: 763.424316  [23744/60000]\n",
            "loss: 1686.803955  [24384/60000]\n",
            "loss: 921.871826  [25024/60000]\n",
            "loss: 1119.817871  [25664/60000]\n",
            "loss: 2171.830078  [26304/60000]\n",
            "loss: 1041.359253  [26944/60000]\n",
            "loss: 900.982056  [27584/60000]\n",
            "loss: 590.375061  [28224/60000]\n",
            "loss: 619.505005  [28864/60000]\n",
            "loss: 1728.537354  [29504/60000]\n",
            "loss: 2140.866211  [30144/60000]\n",
            "loss: 771.331421  [30784/60000]\n",
            "loss: 586.086914  [31424/60000]\n",
            "loss: 906.849121  [32064/60000]\n",
            "loss: 1618.203003  [32704/60000]\n",
            "loss: 511.265503  [33344/60000]\n",
            "loss: 1522.561157  [33984/60000]\n",
            "loss: 471.628235  [34624/60000]\n",
            "loss: 312.278534  [35264/60000]\n",
            "loss: 700.467590  [35904/60000]\n",
            "loss: 1201.044189  [36544/60000]\n",
            "loss: 2983.109131  [37184/60000]\n",
            "loss: 387.801208  [37824/60000]\n",
            "loss: 1005.016846  [38464/60000]\n",
            "loss: 1014.631226  [39104/60000]\n",
            "loss: 1153.639893  [39744/60000]\n",
            "loss: 2189.130371  [40384/60000]\n",
            "loss: 525.532593  [41024/60000]\n",
            "loss: 903.896790  [41664/60000]\n",
            "loss: 1541.834961  [42304/60000]\n",
            "loss: 501.326172  [42944/60000]\n",
            "loss: 544.396057  [43584/60000]\n",
            "loss: 2191.351318  [44224/60000]\n",
            "loss: 1038.108765  [44864/60000]\n",
            "loss: 657.428040  [45504/60000]\n",
            "loss: 921.866821  [46144/60000]\n",
            "loss: 1099.614502  [46784/60000]\n",
            "loss: 1853.021973  [47424/60000]\n",
            "loss: 1264.891357  [48064/60000]\n",
            "loss: 643.078003  [48704/60000]\n",
            "loss: 1303.693359  [49344/60000]\n",
            "loss: 2270.109131  [49984/60000]\n",
            "loss: 631.559814  [50624/60000]\n",
            "loss: 1538.832520  [51264/60000]\n",
            "loss: 2197.616455  [51904/60000]\n",
            "loss: 3805.993652  [52544/60000]\n",
            "loss: 787.777710  [53184/60000]\n",
            "loss: 1034.954102  [53824/60000]\n",
            "loss: 2239.561523  [54464/60000]\n",
            "loss: 836.188843  [55104/60000]\n",
            "loss: 717.914551  [55744/60000]\n",
            "loss: 858.179565  [56384/60000]\n",
            "loss: 986.520325  [57024/60000]\n",
            "loss: 1045.618652  [57664/60000]\n",
            "loss: 634.561584  [58304/60000]\n",
            "loss: 786.514160  [58944/60000]\n",
            "loss: 4310.182129  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.5%, Avg loss: 2418.267732 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1834.102051  [   64/60000]\n",
            "loss: 1121.965454  [  704/60000]\n",
            "loss: 435.820068  [ 1344/60000]\n",
            "loss: 625.104492  [ 1984/60000]\n",
            "loss: 1125.272705  [ 2624/60000]\n",
            "loss: 1348.984985  [ 3264/60000]\n",
            "loss: 1133.500977  [ 3904/60000]\n",
            "loss: 476.310577  [ 4544/60000]\n",
            "loss: 1200.240356  [ 5184/60000]\n",
            "loss: 862.852722  [ 5824/60000]\n",
            "loss: 608.097412  [ 6464/60000]\n",
            "loss: 867.442749  [ 7104/60000]\n",
            "loss: 1689.676025  [ 7744/60000]\n",
            "loss: 1213.633545  [ 8384/60000]\n",
            "loss: 903.452576  [ 9024/60000]\n",
            "loss: 723.151978  [ 9664/60000]\n",
            "loss: 919.642700  [10304/60000]\n",
            "loss: 1196.788086  [10944/60000]\n",
            "loss: 1009.325256  [11584/60000]\n",
            "loss: 4049.899170  [12224/60000]\n",
            "loss: 964.651733  [12864/60000]\n",
            "loss: 1032.629761  [13504/60000]\n",
            "loss: 1625.703369  [14144/60000]\n",
            "loss: 872.363159  [14784/60000]\n",
            "loss: 654.228699  [15424/60000]\n",
            "loss: 826.938721  [16064/60000]\n",
            "loss: 406.766479  [16704/60000]\n",
            "loss: 1323.528931  [17344/60000]\n",
            "loss: 894.846985  [17984/60000]\n",
            "loss: 534.652832  [18624/60000]\n",
            "loss: 1247.684082  [19264/60000]\n",
            "loss: 1204.168213  [19904/60000]\n",
            "loss: 703.394714  [20544/60000]\n",
            "loss: 980.630493  [21184/60000]\n",
            "loss: 2363.227051  [21824/60000]\n",
            "loss: 1721.604492  [22464/60000]\n",
            "loss: 1139.849609  [23104/60000]\n",
            "loss: 899.208374  [23744/60000]\n",
            "loss: 1354.005737  [24384/60000]\n",
            "loss: 822.146484  [25024/60000]\n",
            "loss: 885.707520  [25664/60000]\n",
            "loss: 2401.586426  [26304/60000]\n",
            "loss: 1002.938477  [26944/60000]\n",
            "loss: 1573.893677  [27584/60000]\n",
            "loss: 523.351624  [28224/60000]\n",
            "loss: 419.088898  [28864/60000]\n",
            "loss: 1986.389771  [29504/60000]\n",
            "loss: 2027.686279  [30144/60000]\n",
            "loss: 1223.242432  [30784/60000]\n",
            "loss: 342.664490  [31424/60000]\n",
            "loss: 889.916321  [32064/60000]\n",
            "loss: 805.058838  [32704/60000]\n",
            "loss: 478.161865  [33344/60000]\n",
            "loss: 1949.048096  [33984/60000]\n",
            "loss: 491.137390  [34624/60000]\n",
            "loss: 488.549316  [35264/60000]\n",
            "loss: 1009.249023  [35904/60000]\n",
            "loss: 1089.165649  [36544/60000]\n",
            "loss: 1206.814453  [37184/60000]\n",
            "loss: 665.562988  [37824/60000]\n",
            "loss: 1597.910034  [38464/60000]\n",
            "loss: 1104.685791  [39104/60000]\n",
            "loss: 1382.065674  [39744/60000]\n",
            "loss: 1009.098389  [40384/60000]\n",
            "loss: 1979.511230  [41024/60000]\n",
            "loss: 1030.423462  [41664/60000]\n",
            "loss: 1768.150635  [42304/60000]\n",
            "loss: 2442.064941  [42944/60000]\n",
            "loss: 2182.427490  [43584/60000]\n",
            "loss: 1842.015137  [44224/60000]\n",
            "loss: 1250.872803  [44864/60000]\n",
            "loss: 948.430298  [45504/60000]\n",
            "loss: 811.439209  [46144/60000]\n",
            "loss: 1114.462891  [46784/60000]\n",
            "loss: 472.298553  [47424/60000]\n",
            "loss: 1282.005737  [48064/60000]\n",
            "loss: 966.881348  [48704/60000]\n",
            "loss: 552.521057  [49344/60000]\n",
            "loss: 1441.239990  [49984/60000]\n",
            "loss: 975.972961  [50624/60000]\n",
            "loss: 1094.526489  [51264/60000]\n",
            "loss: 1537.219971  [51904/60000]\n",
            "loss: 4400.244141  [52544/60000]\n",
            "loss: 1023.656311  [53184/60000]\n",
            "loss: 644.660828  [53824/60000]\n",
            "loss: 2396.130127  [54464/60000]\n",
            "loss: 1344.047607  [55104/60000]\n",
            "loss: 964.146118  [55744/60000]\n",
            "loss: 522.209839  [56384/60000]\n",
            "loss: 1246.537964  [57024/60000]\n",
            "loss: 1525.995483  [57664/60000]\n",
            "loss: 744.610352  [58304/60000]\n",
            "loss: 940.309814  [58944/60000]\n",
            "loss: 3707.438477  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.7%, Avg loss: 3265.505806 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 2666.928467  [   64/60000]\n",
            "loss: 781.720520  [  704/60000]\n",
            "loss: 455.289062  [ 1344/60000]\n",
            "loss: 672.706238  [ 1984/60000]\n",
            "loss: 1197.587280  [ 2624/60000]\n",
            "loss: 1034.413818  [ 3264/60000]\n",
            "loss: 994.860046  [ 3904/60000]\n",
            "loss: 575.798645  [ 4544/60000]\n",
            "loss: 1986.310791  [ 5184/60000]\n",
            "loss: 626.379272  [ 5824/60000]\n",
            "loss: 446.380554  [ 6464/60000]\n",
            "loss: 1670.857178  [ 7104/60000]\n",
            "loss: 2361.704102  [ 7744/60000]\n",
            "loss: 964.892395  [ 8384/60000]\n",
            "loss: 1112.326538  [ 9024/60000]\n",
            "loss: 784.895081  [ 9664/60000]\n",
            "loss: 2304.766357  [10304/60000]\n",
            "loss: 552.715332  [10944/60000]\n",
            "loss: 867.889160  [11584/60000]\n",
            "loss: 1860.123047  [12224/60000]\n",
            "loss: 1276.822754  [12864/60000]\n",
            "loss: 1297.527832  [13504/60000]\n",
            "loss: 485.722870  [14144/60000]\n",
            "loss: 885.635620  [14784/60000]\n",
            "loss: 147.081940  [15424/60000]\n",
            "loss: 1501.589355  [16064/60000]\n",
            "loss: 1436.834839  [16704/60000]\n",
            "loss: 1380.819458  [17344/60000]\n",
            "loss: 1179.739014  [17984/60000]\n",
            "loss: 502.233307  [18624/60000]\n",
            "loss: 615.533203  [19264/60000]\n",
            "loss: 1227.492798  [19904/60000]\n",
            "loss: 461.009583  [20544/60000]\n",
            "loss: 1039.354248  [21184/60000]\n",
            "loss: 2560.128174  [21824/60000]\n",
            "loss: 1009.054321  [22464/60000]\n",
            "loss: 1263.767212  [23104/60000]\n",
            "loss: 802.664673  [23744/60000]\n",
            "loss: 1616.088501  [24384/60000]\n",
            "loss: 751.624451  [25024/60000]\n",
            "loss: 1030.361572  [25664/60000]\n",
            "loss: 1826.413940  [26304/60000]\n",
            "loss: 1474.542725  [26944/60000]\n",
            "loss: 1551.866699  [27584/60000]\n",
            "loss: 612.602844  [28224/60000]\n",
            "loss: 341.942993  [28864/60000]\n",
            "loss: 2693.392090  [29504/60000]\n",
            "loss: 1911.451294  [30144/60000]\n",
            "loss: 740.499756  [30784/60000]\n",
            "loss: 360.883118  [31424/60000]\n",
            "loss: 1397.944336  [32064/60000]\n",
            "loss: 664.376099  [32704/60000]\n",
            "loss: 457.432068  [33344/60000]\n",
            "loss: 1847.191406  [33984/60000]\n",
            "loss: 428.635376  [34624/60000]\n",
            "loss: 398.319366  [35264/60000]\n",
            "loss: 1072.205200  [35904/60000]\n",
            "loss: 1196.210083  [36544/60000]\n",
            "loss: 859.976013  [37184/60000]\n",
            "loss: 477.249542  [37824/60000]\n",
            "loss: 2026.846802  [38464/60000]\n",
            "loss: 612.804077  [39104/60000]\n",
            "loss: 1354.150879  [39744/60000]\n",
            "loss: 1124.328735  [40384/60000]\n",
            "loss: 1845.497803  [41024/60000]\n",
            "loss: 981.753784  [41664/60000]\n",
            "loss: 1687.123779  [42304/60000]\n",
            "loss: 2456.298828  [42944/60000]\n",
            "loss: 2420.323730  [43584/60000]\n",
            "loss: 2173.621338  [44224/60000]\n",
            "loss: 1290.475952  [44864/60000]\n",
            "loss: 1048.122070  [45504/60000]\n",
            "loss: 657.476929  [46144/60000]\n",
            "loss: 1049.031006  [46784/60000]\n",
            "loss: 390.831177  [47424/60000]\n",
            "loss: 1131.230225  [48064/60000]\n",
            "loss: 1106.296631  [48704/60000]\n",
            "loss: 762.046570  [49344/60000]\n",
            "loss: 1284.117310  [49984/60000]\n",
            "loss: 563.378601  [50624/60000]\n",
            "loss: 2241.992920  [51264/60000]\n",
            "loss: 1373.638306  [51904/60000]\n",
            "loss: 2576.415039  [52544/60000]\n",
            "loss: 348.109283  [53184/60000]\n",
            "loss: 1229.739624  [53824/60000]\n",
            "loss: 1200.766357  [54464/60000]\n",
            "loss: 409.688110  [55104/60000]\n",
            "loss: 3714.343262  [55744/60000]\n",
            "loss: 748.302124  [56384/60000]\n",
            "loss: 947.406006  [57024/60000]\n",
            "loss: 1343.207153  [57664/60000]\n",
            "loss: 526.040405  [58304/60000]\n",
            "loss: 735.971924  [58944/60000]\n",
            "loss: 1846.159424  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.1%, Avg loss: 2938.559641 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 2256.223145  [   64/60000]\n",
            "loss: 606.506714  [  704/60000]\n",
            "loss: 398.191895  [ 1344/60000]\n",
            "loss: 1433.951172  [ 1984/60000]\n",
            "loss: 1028.391357  [ 2624/60000]\n",
            "loss: 941.328125  [ 3264/60000]\n",
            "loss: 1319.011719  [ 3904/60000]\n",
            "loss: 1207.792969  [ 4544/60000]\n",
            "loss: 1359.363892  [ 5184/60000]\n",
            "loss: 1809.611328  [ 5824/60000]\n",
            "loss: 546.194763  [ 6464/60000]\n",
            "loss: 675.205017  [ 7104/60000]\n",
            "loss: 2276.011719  [ 7744/60000]\n",
            "loss: 1090.276733  [ 8384/60000]\n",
            "loss: 1319.600342  [ 9024/60000]\n",
            "loss: 1262.632446  [ 9664/60000]\n",
            "loss: 2464.725098  [10304/60000]\n",
            "loss: 714.916992  [10944/60000]\n",
            "loss: 983.746704  [11584/60000]\n",
            "loss: 2059.289795  [12224/60000]\n",
            "loss: 1523.386841  [12864/60000]\n",
            "loss: 1444.493042  [13504/60000]\n",
            "loss: 448.300934  [14144/60000]\n",
            "loss: 795.379333  [14784/60000]\n",
            "loss: 214.819778  [15424/60000]\n",
            "loss: 2027.162231  [16064/60000]\n",
            "loss: 560.035217  [16704/60000]\n",
            "loss: 1219.986694  [17344/60000]\n",
            "loss: 904.105408  [17984/60000]\n",
            "loss: 755.640991  [18624/60000]\n",
            "loss: 712.815002  [19264/60000]\n",
            "loss: 1006.229614  [19904/60000]\n",
            "loss: 503.261719  [20544/60000]\n",
            "loss: 1082.410278  [21184/60000]\n",
            "loss: 3430.057861  [21824/60000]\n",
            "loss: 1208.221191  [22464/60000]\n",
            "loss: 511.249481  [23104/60000]\n",
            "loss: 810.979187  [23744/60000]\n",
            "loss: 969.049255  [24384/60000]\n",
            "loss: 680.681335  [25024/60000]\n",
            "loss: 1201.816162  [25664/60000]\n",
            "loss: 2318.132080  [26304/60000]\n",
            "loss: 1123.788452  [26944/60000]\n",
            "loss: 1216.392456  [27584/60000]\n",
            "loss: 623.796082  [28224/60000]\n",
            "loss: 372.686829  [28864/60000]\n",
            "loss: 1702.387939  [29504/60000]\n",
            "loss: 1484.452026  [30144/60000]\n",
            "loss: 986.379517  [30784/60000]\n",
            "loss: 345.788788  [31424/60000]\n",
            "loss: 798.430786  [32064/60000]\n",
            "loss: 1428.190918  [32704/60000]\n",
            "loss: 446.421783  [33344/60000]\n",
            "loss: 1089.538208  [33984/60000]\n",
            "loss: 438.405396  [34624/60000]\n",
            "loss: 409.485138  [35264/60000]\n",
            "loss: 981.958801  [35904/60000]\n",
            "loss: 736.037781  [36544/60000]\n",
            "loss: 2559.587891  [37184/60000]\n",
            "loss: 469.152283  [37824/60000]\n",
            "loss: 1070.098145  [38464/60000]\n",
            "loss: 969.642822  [39104/60000]\n",
            "loss: 1186.711792  [39744/60000]\n",
            "loss: 961.949646  [40384/60000]\n",
            "loss: 1038.841797  [41024/60000]\n",
            "loss: 1325.300171  [41664/60000]\n",
            "loss: 1031.849365  [42304/60000]\n",
            "loss: 1007.562378  [42944/60000]\n",
            "loss: 1135.544067  [43584/60000]\n",
            "loss: 1073.952148  [44224/60000]\n",
            "loss: 1204.118652  [44864/60000]\n",
            "loss: 708.852173  [45504/60000]\n",
            "loss: 1725.874268  [46144/60000]\n",
            "loss: 1178.810913  [46784/60000]\n",
            "loss: 721.882629  [47424/60000]\n",
            "loss: 1165.236328  [48064/60000]\n",
            "loss: 788.524048  [48704/60000]\n",
            "loss: 863.192017  [49344/60000]\n",
            "loss: 1081.065308  [49984/60000]\n",
            "loss: 460.132904  [50624/60000]\n",
            "loss: 2211.746094  [51264/60000]\n",
            "loss: 3074.254639  [51904/60000]\n",
            "loss: 2231.412598  [52544/60000]\n",
            "loss: 707.533569  [53184/60000]\n",
            "loss: 1045.809326  [53824/60000]\n",
            "loss: 610.820007  [54464/60000]\n",
            "loss: 653.242432  [55104/60000]\n",
            "loss: 1180.790039  [55744/60000]\n",
            "loss: 916.106750  [56384/60000]\n",
            "loss: 1045.885986  [57024/60000]\n",
            "loss: 1188.779175  [57664/60000]\n",
            "loss: 913.085571  [58304/60000]\n",
            "loss: 773.223022  [58944/60000]\n",
            "loss: 2588.148438  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 70.2%, Avg loss: 2228.372213 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1499.438354  [   64/60000]\n",
            "loss: 587.846436  [  704/60000]\n",
            "loss: 323.901672  [ 1344/60000]\n",
            "loss: 671.560120  [ 1984/60000]\n",
            "loss: 980.778076  [ 2624/60000]\n",
            "loss: 1026.583008  [ 3264/60000]\n",
            "loss: 1230.178955  [ 3904/60000]\n",
            "loss: 996.479004  [ 4544/60000]\n",
            "loss: 1300.569702  [ 5184/60000]\n",
            "loss: 448.001526  [ 5824/60000]\n",
            "loss: 266.814484  [ 6464/60000]\n",
            "loss: 1035.769653  [ 7104/60000]\n",
            "loss: 2947.910889  [ 7744/60000]\n",
            "loss: 2148.890137  [ 8384/60000]\n",
            "loss: 703.538452  [ 9024/60000]\n",
            "loss: 1547.529175  [ 9664/60000]\n",
            "loss: 1470.206299  [10304/60000]\n",
            "loss: 611.633118  [10944/60000]\n",
            "loss: 1284.454468  [11584/60000]\n",
            "loss: 2064.229980  [12224/60000]\n",
            "loss: 2982.193848  [12864/60000]\n",
            "loss: 1424.101685  [13504/60000]\n",
            "loss: 660.279175  [14144/60000]\n",
            "loss: 905.944031  [14784/60000]\n",
            "loss: 259.327942  [15424/60000]\n",
            "loss: 851.859863  [16064/60000]\n",
            "loss: 1523.847656  [16704/60000]\n",
            "loss: 1357.697021  [17344/60000]\n",
            "loss: 1230.185547  [17984/60000]\n",
            "loss: 502.889282  [18624/60000]\n",
            "loss: 1324.716187  [19264/60000]\n",
            "loss: 1764.935425  [19904/60000]\n",
            "loss: 495.659607  [20544/60000]\n",
            "loss: 973.265198  [21184/60000]\n",
            "loss: 1642.558105  [21824/60000]\n",
            "loss: 838.412415  [22464/60000]\n",
            "loss: 2659.913818  [23104/60000]\n",
            "loss: 679.078491  [23744/60000]\n",
            "loss: 1995.331665  [24384/60000]\n",
            "loss: 671.204895  [25024/60000]\n",
            "loss: 1526.957520  [25664/60000]\n",
            "loss: 2044.985107  [26304/60000]\n",
            "loss: 1114.170898  [26944/60000]\n",
            "loss: 1474.484619  [27584/60000]\n",
            "loss: 486.180878  [28224/60000]\n",
            "loss: 413.726196  [28864/60000]\n",
            "loss: 1542.262085  [29504/60000]\n",
            "loss: 1907.875244  [30144/60000]\n",
            "loss: 1197.111572  [30784/60000]\n",
            "loss: 521.973999  [31424/60000]\n",
            "loss: 1009.370728  [32064/60000]\n",
            "loss: 612.880371  [32704/60000]\n",
            "loss: 469.616425  [33344/60000]\n",
            "loss: 1374.645874  [33984/60000]\n",
            "loss: 599.644043  [34624/60000]\n",
            "loss: 560.921997  [35264/60000]\n",
            "loss: 682.453857  [35904/60000]\n",
            "loss: 716.747498  [36544/60000]\n",
            "loss: 2325.684570  [37184/60000]\n",
            "loss: 468.231628  [37824/60000]\n",
            "loss: 1086.425659  [38464/60000]\n",
            "loss: 1574.846313  [39104/60000]\n",
            "loss: 774.683228  [39744/60000]\n",
            "loss: 884.199829  [40384/60000]\n",
            "loss: 2012.544556  [41024/60000]\n",
            "loss: 2395.548584  [41664/60000]\n",
            "loss: 2072.845215  [42304/60000]\n",
            "loss: 2053.029297  [42944/60000]\n",
            "loss: 771.967163  [43584/60000]\n",
            "loss: 1594.115723  [44224/60000]\n",
            "loss: 1435.213135  [44864/60000]\n",
            "loss: 669.719299  [45504/60000]\n",
            "loss: 825.033691  [46144/60000]\n",
            "loss: 1086.102295  [46784/60000]\n",
            "loss: 755.896851  [47424/60000]\n",
            "loss: 1097.458618  [48064/60000]\n",
            "loss: 938.074646  [48704/60000]\n",
            "loss: 637.567871  [49344/60000]\n",
            "loss: 1252.093750  [49984/60000]\n",
            "loss: 529.566406  [50624/60000]\n",
            "loss: 1039.080444  [51264/60000]\n",
            "loss: 2058.692139  [51904/60000]\n",
            "loss: 3475.817139  [52544/60000]\n",
            "loss: 642.916321  [53184/60000]\n",
            "loss: 494.433594  [53824/60000]\n",
            "loss: 912.300171  [54464/60000]\n",
            "loss: 746.780334  [55104/60000]\n",
            "loss: 912.015076  [55744/60000]\n",
            "loss: 429.160889  [56384/60000]\n",
            "loss: 656.176331  [57024/60000]\n",
            "loss: 1001.561829  [57664/60000]\n",
            "loss: 402.424316  [58304/60000]\n",
            "loss: 590.041321  [58944/60000]\n",
            "loss: 2519.170898  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 73.0%, Avg loss: 1537.938641 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 905.217407  [   64/60000]\n",
            "loss: 904.152344  [  704/60000]\n",
            "loss: 307.636993  [ 1344/60000]\n",
            "loss: 850.566223  [ 1984/60000]\n",
            "loss: 1211.323853  [ 2624/60000]\n",
            "loss: 849.817322  [ 3264/60000]\n",
            "loss: 1352.312500  [ 3904/60000]\n",
            "loss: 1634.819824  [ 4544/60000]\n",
            "loss: 1494.334351  [ 5184/60000]\n",
            "loss: 718.155212  [ 5824/60000]\n",
            "loss: 239.861404  [ 6464/60000]\n",
            "loss: 956.824097  [ 7104/60000]\n",
            "loss: 1186.099243  [ 7744/60000]\n",
            "loss: 1244.970093  [ 8384/60000]\n",
            "loss: 1011.993530  [ 9024/60000]\n",
            "loss: 489.722168  [ 9664/60000]\n",
            "loss: 1483.467896  [10304/60000]\n",
            "loss: 3763.244629  [10944/60000]\n",
            "loss: 1079.982422  [11584/60000]\n",
            "loss: 2219.283936  [12224/60000]\n",
            "loss: 460.590881  [12864/60000]\n",
            "loss: 1893.119751  [13504/60000]\n",
            "loss: 1402.954834  [14144/60000]\n",
            "loss: 1748.975586  [14784/60000]\n",
            "loss: 339.626038  [15424/60000]\n",
            "loss: 1600.097778  [16064/60000]\n",
            "loss: 536.001831  [16704/60000]\n",
            "loss: 1230.014160  [17344/60000]\n",
            "loss: 1527.564209  [17984/60000]\n",
            "loss: 705.452393  [18624/60000]\n",
            "loss: 1940.972412  [19264/60000]\n",
            "loss: 1541.031616  [19904/60000]\n",
            "loss: 519.492188  [20544/60000]\n",
            "loss: 834.801147  [21184/60000]\n",
            "loss: 3337.484375  [21824/60000]\n",
            "loss: 1629.340210  [22464/60000]\n",
            "loss: 1534.697632  [23104/60000]\n",
            "loss: 790.198486  [23744/60000]\n",
            "loss: 990.716370  [24384/60000]\n",
            "loss: 662.335205  [25024/60000]\n",
            "loss: 1826.550659  [25664/60000]\n",
            "loss: 1922.451294  [26304/60000]\n",
            "loss: 1006.487549  [26944/60000]\n",
            "loss: 1852.677002  [27584/60000]\n",
            "loss: 551.699951  [28224/60000]\n",
            "loss: 1419.935669  [28864/60000]\n",
            "loss: 1382.875732  [29504/60000]\n",
            "loss: 1930.288330  [30144/60000]\n",
            "loss: 681.610962  [30784/60000]\n",
            "loss: 586.927429  [31424/60000]\n",
            "loss: 880.042114  [32064/60000]\n",
            "loss: 696.509033  [32704/60000]\n",
            "loss: 552.663452  [33344/60000]\n",
            "loss: 1221.514771  [33984/60000]\n",
            "loss: 418.470398  [34624/60000]\n",
            "loss: 443.313904  [35264/60000]\n",
            "loss: 793.770386  [35904/60000]\n",
            "loss: 1657.225098  [36544/60000]\n",
            "loss: 2077.895752  [37184/60000]\n",
            "loss: 600.516602  [37824/60000]\n",
            "loss: 1443.377686  [38464/60000]\n",
            "loss: 963.999512  [39104/60000]\n",
            "loss: 1641.092651  [39744/60000]\n",
            "loss: 1954.619629  [40384/60000]\n",
            "loss: 1294.537109  [41024/60000]\n",
            "loss: 3849.384277  [41664/60000]\n",
            "loss: 1094.408813  [42304/60000]\n",
            "loss: 994.263184  [42944/60000]\n",
            "loss: 869.550659  [43584/60000]\n",
            "loss: 2957.627686  [44224/60000]\n",
            "loss: 819.075989  [44864/60000]\n",
            "loss: 640.581177  [45504/60000]\n",
            "loss: 1300.302612  [46144/60000]\n",
            "loss: 1393.909058  [46784/60000]\n",
            "loss: 1206.997925  [47424/60000]\n",
            "loss: 958.454834  [48064/60000]\n",
            "loss: 794.350098  [48704/60000]\n",
            "loss: 885.100220  [49344/60000]\n",
            "loss: 1092.411499  [49984/60000]\n",
            "loss: 509.647400  [50624/60000]\n",
            "loss: 1494.906250  [51264/60000]\n",
            "loss: 2550.745605  [51904/60000]\n",
            "loss: 2181.407227  [52544/60000]\n",
            "loss: 699.447510  [53184/60000]\n",
            "loss: 719.905212  [53824/60000]\n",
            "loss: 1008.380493  [54464/60000]\n",
            "loss: 352.446838  [55104/60000]\n",
            "loss: 910.749512  [55744/60000]\n",
            "loss: 581.792114  [56384/60000]\n",
            "loss: 1137.295532  [57024/60000]\n",
            "loss: 1285.081177  [57664/60000]\n",
            "loss: 377.956055  [58304/60000]\n",
            "loss: 764.641968  [58944/60000]\n",
            "loss: 1776.073608  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.0%, Avg loss: 3219.448588 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 2513.715576  [   64/60000]\n",
            "loss: 1067.553223  [  704/60000]\n",
            "loss: 882.478699  [ 1344/60000]\n",
            "loss: 697.073364  [ 1984/60000]\n",
            "loss: 909.246277  [ 2624/60000]\n",
            "loss: 739.925903  [ 3264/60000]\n",
            "loss: 1215.778076  [ 3904/60000]\n",
            "loss: 761.299744  [ 4544/60000]\n",
            "loss: 2432.047607  [ 5184/60000]\n",
            "loss: 1289.764526  [ 5824/60000]\n",
            "loss: 344.159790  [ 6464/60000]\n",
            "loss: 1011.559753  [ 7104/60000]\n",
            "loss: 2706.777344  [ 7744/60000]\n",
            "loss: 1175.052002  [ 8384/60000]\n",
            "loss: 1101.859131  [ 9024/60000]\n",
            "loss: 816.653015  [ 9664/60000]\n",
            "loss: 901.333740  [10304/60000]\n",
            "loss: 827.152771  [10944/60000]\n",
            "loss: 802.181396  [11584/60000]\n",
            "loss: 4212.268555  [12224/60000]\n",
            "loss: 1268.921509  [12864/60000]\n",
            "loss: 1544.806763  [13504/60000]\n",
            "loss: 426.720947  [14144/60000]\n",
            "loss: 1295.707520  [14784/60000]\n",
            "loss: 673.894897  [15424/60000]\n",
            "loss: 670.325134  [16064/60000]\n",
            "loss: 1290.000244  [16704/60000]\n",
            "loss: 1254.369385  [17344/60000]\n",
            "loss: 1151.887939  [17984/60000]\n",
            "loss: 687.101074  [18624/60000]\n",
            "loss: 1393.613770  [19264/60000]\n",
            "loss: 1591.289795  [19904/60000]\n",
            "loss: 492.629456  [20544/60000]\n",
            "loss: 864.937561  [21184/60000]\n",
            "loss: 3084.033691  [21824/60000]\n",
            "loss: 738.378662  [22464/60000]\n",
            "loss: 1200.914307  [23104/60000]\n",
            "loss: 777.574341  [23744/60000]\n",
            "loss: 1268.325439  [24384/60000]\n",
            "loss: 789.802856  [25024/60000]\n",
            "loss: 1068.048218  [25664/60000]\n",
            "loss: 2308.061279  [26304/60000]\n",
            "loss: 1301.903198  [26944/60000]\n",
            "loss: 2152.035156  [27584/60000]\n",
            "loss: 1054.342529  [28224/60000]\n",
            "loss: 375.499695  [28864/60000]\n",
            "loss: 1308.491455  [29504/60000]\n",
            "loss: 1695.187012  [30144/60000]\n",
            "loss: 809.866821  [30784/60000]\n",
            "loss: 512.769653  [31424/60000]\n",
            "loss: 1592.814941  [32064/60000]\n",
            "loss: 914.579834  [32704/60000]\n",
            "loss: 659.342896  [33344/60000]\n",
            "loss: 1141.267090  [33984/60000]\n",
            "loss: 309.583069  [34624/60000]\n",
            "loss: 355.685333  [35264/60000]\n",
            "loss: 723.689392  [35904/60000]\n",
            "loss: 901.069092  [36544/60000]\n",
            "loss: 2313.283203  [37184/60000]\n",
            "loss: 524.295959  [37824/60000]\n",
            "loss: 1181.614990  [38464/60000]\n",
            "loss: 473.591675  [39104/60000]\n",
            "loss: 865.940979  [39744/60000]\n",
            "loss: 1088.909424  [40384/60000]\n",
            "loss: 1699.866577  [41024/60000]\n",
            "loss: 3843.554688  [41664/60000]\n",
            "loss: 1328.021851  [42304/60000]\n",
            "loss: 1495.628906  [42944/60000]\n",
            "loss: 632.574097  [43584/60000]\n",
            "loss: 1729.032837  [44224/60000]\n",
            "loss: 1332.061279  [44864/60000]\n",
            "loss: 787.743774  [45504/60000]\n",
            "loss: 1535.971191  [46144/60000]\n",
            "loss: 1552.604736  [46784/60000]\n",
            "loss: 649.430725  [47424/60000]\n",
            "loss: 1216.056152  [48064/60000]\n",
            "loss: 739.637939  [48704/60000]\n",
            "loss: 682.137390  [49344/60000]\n",
            "loss: 1046.759766  [49984/60000]\n",
            "loss: 807.853821  [50624/60000]\n",
            "loss: 1748.673828  [51264/60000]\n",
            "loss: 2997.306641  [51904/60000]\n",
            "loss: 1944.343750  [52544/60000]\n",
            "loss: 2728.014648  [53184/60000]\n",
            "loss: 1195.919067  [53824/60000]\n",
            "loss: 555.695923  [54464/60000]\n",
            "loss: 876.501221  [55104/60000]\n",
            "loss: 686.025085  [55744/60000]\n",
            "loss: 494.768768  [56384/60000]\n",
            "loss: 1133.852173  [57024/60000]\n",
            "loss: 1012.925903  [57664/60000]\n",
            "loss: 373.502014  [58304/60000]\n",
            "loss: 643.419067  [58944/60000]\n",
            "loss: 2583.909180  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 70.9%, Avg loss: 2000.726744 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1281.066406  [   64/60000]\n",
            "loss: 712.622192  [  704/60000]\n",
            "loss: 385.774750  [ 1344/60000]\n",
            "loss: 503.800781  [ 1984/60000]\n",
            "loss: 1195.524658  [ 2624/60000]\n",
            "loss: 960.414917  [ 3264/60000]\n",
            "loss: 1127.877197  [ 3904/60000]\n",
            "loss: 673.079346  [ 4544/60000]\n",
            "loss: 1357.765259  [ 5184/60000]\n",
            "loss: 1317.446045  [ 5824/60000]\n",
            "loss: 334.201508  [ 6464/60000]\n",
            "loss: 912.649536  [ 7104/60000]\n",
            "loss: 1082.423462  [ 7744/60000]\n",
            "loss: 1407.275757  [ 8384/60000]\n",
            "loss: 1041.971313  [ 9024/60000]\n",
            "loss: 860.542725  [ 9664/60000]\n",
            "loss: 1355.352173  [10304/60000]\n",
            "loss: 1162.236328  [10944/60000]\n",
            "loss: 1408.365601  [11584/60000]\n",
            "loss: 1963.458252  [12224/60000]\n",
            "loss: 923.525391  [12864/60000]\n",
            "loss: 955.905212  [13504/60000]\n",
            "loss: 442.154236  [14144/60000]\n",
            "loss: 1857.489258  [14784/60000]\n",
            "loss: 821.273132  [15424/60000]\n",
            "loss: 1254.928223  [16064/60000]\n",
            "loss: 549.168823  [16704/60000]\n",
            "loss: 1137.491211  [17344/60000]\n",
            "loss: 994.120728  [17984/60000]\n",
            "loss: 556.892212  [18624/60000]\n",
            "loss: 1284.348633  [19264/60000]\n",
            "loss: 1156.428955  [19904/60000]\n",
            "loss: 549.226746  [20544/60000]\n",
            "loss: 950.662720  [21184/60000]\n",
            "loss: 3154.465332  [21824/60000]\n",
            "loss: 1052.951660  [22464/60000]\n",
            "loss: 1375.145874  [23104/60000]\n",
            "loss: 785.717468  [23744/60000]\n",
            "loss: 878.383057  [24384/60000]\n",
            "loss: 599.640869  [25024/60000]\n",
            "loss: 1112.079224  [25664/60000]\n",
            "loss: 1824.968262  [26304/60000]\n",
            "loss: 982.099609  [26944/60000]\n",
            "loss: 1449.451416  [27584/60000]\n",
            "loss: 483.597412  [28224/60000]\n",
            "loss: 536.320679  [28864/60000]\n",
            "loss: 1506.453857  [29504/60000]\n",
            "loss: 1365.109375  [30144/60000]\n",
            "loss: 619.096191  [30784/60000]\n",
            "loss: 320.470245  [31424/60000]\n",
            "loss: 899.640686  [32064/60000]\n",
            "loss: 755.659424  [32704/60000]\n",
            "loss: 395.949341  [33344/60000]\n",
            "loss: 1551.425659  [33984/60000]\n",
            "loss: 394.390289  [34624/60000]\n",
            "loss: 575.016052  [35264/60000]\n",
            "loss: 1509.275879  [35904/60000]\n",
            "loss: 883.138062  [36544/60000]\n",
            "loss: 2240.654785  [37184/60000]\n",
            "loss: 346.042175  [37824/60000]\n",
            "loss: 1088.203979  [38464/60000]\n",
            "loss: 1352.636353  [39104/60000]\n",
            "loss: 1943.262939  [39744/60000]\n",
            "loss: 1933.152100  [40384/60000]\n",
            "loss: 1307.041992  [41024/60000]\n",
            "loss: 1182.998047  [41664/60000]\n",
            "loss: 1133.705322  [42304/60000]\n",
            "loss: 691.597900  [42944/60000]\n",
            "loss: 493.357239  [43584/60000]\n",
            "loss: 1933.265869  [44224/60000]\n",
            "loss: 968.120850  [44864/60000]\n",
            "loss: 1282.951660  [45504/60000]\n",
            "loss: 1007.884094  [46144/60000]\n",
            "loss: 1121.670898  [46784/60000]\n",
            "loss: 476.921753  [47424/60000]\n",
            "loss: 911.310181  [48064/60000]\n",
            "loss: 771.614990  [48704/60000]\n",
            "loss: 666.982544  [49344/60000]\n",
            "loss: 1343.194458  [49984/60000]\n",
            "loss: 632.534668  [50624/60000]\n",
            "loss: 1163.482788  [51264/60000]\n",
            "loss: 1006.215149  [51904/60000]\n",
            "loss: 2569.780273  [52544/60000]\n",
            "loss: 1682.948975  [53184/60000]\n",
            "loss: 663.042236  [53824/60000]\n",
            "loss: 635.096191  [54464/60000]\n",
            "loss: 357.862488  [55104/60000]\n",
            "loss: 1359.979614  [55744/60000]\n",
            "loss: 599.753296  [56384/60000]\n",
            "loss: 833.896790  [57024/60000]\n",
            "loss: 1807.253296  [57664/60000]\n",
            "loss: 349.088928  [58304/60000]\n",
            "loss: 658.934998  [58944/60000]\n",
            "loss: 2035.858643  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 73.1%, Avg loss: 2275.716950 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1820.891235  [   64/60000]\n",
            "loss: 872.205872  [  704/60000]\n",
            "loss: 232.406738  [ 1344/60000]\n",
            "loss: 1023.231567  [ 1984/60000]\n",
            "loss: 844.834167  [ 2624/60000]\n",
            "loss: 1103.020630  [ 3264/60000]\n",
            "loss: 1182.727051  [ 3904/60000]\n",
            "loss: 1177.510986  [ 4544/60000]\n",
            "loss: 1190.751953  [ 5184/60000]\n",
            "loss: 3100.629395  [ 5824/60000]\n",
            "loss: 543.747681  [ 6464/60000]\n",
            "loss: 1343.192627  [ 7104/60000]\n",
            "loss: 2372.060547  [ 7744/60000]\n",
            "loss: 837.116760  [ 8384/60000]\n",
            "loss: 785.429321  [ 9024/60000]\n",
            "loss: 1187.618408  [ 9664/60000]\n",
            "loss: 1236.348022  [10304/60000]\n",
            "loss: 639.334778  [10944/60000]\n",
            "loss: 1279.121582  [11584/60000]\n",
            "loss: 4856.403320  [12224/60000]\n",
            "loss: 1309.221802  [12864/60000]\n",
            "loss: 1480.742432  [13504/60000]\n",
            "loss: 414.412598  [14144/60000]\n",
            "loss: 857.888245  [14784/60000]\n",
            "loss: 310.453674  [15424/60000]\n",
            "loss: 1902.542114  [16064/60000]\n",
            "loss: 1307.717896  [16704/60000]\n",
            "loss: 1224.671631  [17344/60000]\n",
            "loss: 707.471558  [17984/60000]\n",
            "loss: 868.234497  [18624/60000]\n",
            "loss: 1165.144165  [19264/60000]\n",
            "loss: 2000.246826  [19904/60000]\n",
            "loss: 480.450806  [20544/60000]\n",
            "loss: 893.528992  [21184/60000]\n",
            "loss: 2098.783936  [21824/60000]\n",
            "loss: 757.875366  [22464/60000]\n",
            "loss: 511.898407  [23104/60000]\n",
            "loss: 1016.857178  [23744/60000]\n",
            "loss: 867.229126  [24384/60000]\n",
            "loss: 918.587402  [25024/60000]\n",
            "loss: 1167.223389  [25664/60000]\n",
            "loss: 2202.373047  [26304/60000]\n",
            "loss: 1169.365356  [26944/60000]\n",
            "loss: 2059.338379  [27584/60000]\n",
            "loss: 449.608826  [28224/60000]\n",
            "loss: 564.263916  [28864/60000]\n",
            "loss: 1942.149414  [29504/60000]\n",
            "loss: 1292.277954  [30144/60000]\n",
            "loss: 1531.901123  [30784/60000]\n",
            "loss: 776.794495  [31424/60000]\n",
            "loss: 1266.351562  [32064/60000]\n",
            "loss: 1121.805908  [32704/60000]\n",
            "loss: 707.963867  [33344/60000]\n",
            "loss: 1663.495239  [33984/60000]\n",
            "loss: 402.412598  [34624/60000]\n",
            "loss: 445.686035  [35264/60000]\n",
            "loss: 620.394897  [35904/60000]\n",
            "loss: 986.413086  [36544/60000]\n",
            "loss: 2159.582520  [37184/60000]\n",
            "loss: 420.088379  [37824/60000]\n",
            "loss: 797.655884  [38464/60000]\n",
            "loss: 1168.087158  [39104/60000]\n",
            "loss: 1262.882568  [39744/60000]\n",
            "loss: 2610.660889  [40384/60000]\n",
            "loss: 1735.557251  [41024/60000]\n",
            "loss: 1206.074585  [41664/60000]\n",
            "loss: 991.698059  [42304/60000]\n",
            "loss: 611.495789  [42944/60000]\n",
            "loss: 2139.426025  [43584/60000]\n",
            "loss: 2196.322266  [44224/60000]\n",
            "loss: 804.506775  [44864/60000]\n",
            "loss: 919.497864  [45504/60000]\n",
            "loss: 887.248291  [46144/60000]\n",
            "loss: 1754.040283  [46784/60000]\n",
            "loss: 543.268799  [47424/60000]\n",
            "loss: 1063.011353  [48064/60000]\n",
            "loss: 652.440857  [48704/60000]\n",
            "loss: 642.675903  [49344/60000]\n",
            "loss: 1279.187744  [49984/60000]\n",
            "loss: 1114.119507  [50624/60000]\n",
            "loss: 1273.826538  [51264/60000]\n",
            "loss: 2466.199951  [51904/60000]\n",
            "loss: 2311.333008  [52544/60000]\n",
            "loss: 1318.275879  [53184/60000]\n",
            "loss: 765.528503  [53824/60000]\n",
            "loss: 686.330688  [54464/60000]\n",
            "loss: 587.334839  [55104/60000]\n",
            "loss: 689.530945  [55744/60000]\n",
            "loss: 429.156097  [56384/60000]\n",
            "loss: 892.559204  [57024/60000]\n",
            "loss: 1245.140747  [57664/60000]\n",
            "loss: 318.220398  [58304/60000]\n",
            "loss: 574.799988  [58944/60000]\n",
            "loss: 1605.436890  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.7%, Avg loss: 3256.918889 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 2682.179199  [   64/60000]\n",
            "loss: 893.064026  [  704/60000]\n",
            "loss: 595.553955  [ 1344/60000]\n",
            "loss: 990.788818  [ 1984/60000]\n",
            "loss: 913.973633  [ 2624/60000]\n",
            "loss: 1125.330444  [ 3264/60000]\n",
            "loss: 1419.557617  [ 3904/60000]\n",
            "loss: 907.625000  [ 4544/60000]\n",
            "loss: 1101.828613  [ 5184/60000]\n",
            "loss: 534.501221  [ 5824/60000]\n",
            "loss: 638.218750  [ 6464/60000]\n",
            "loss: 2232.106445  [ 7104/60000]\n",
            "loss: 2825.605469  [ 7744/60000]\n",
            "loss: 981.670471  [ 8384/60000]\n",
            "loss: 811.976990  [ 9024/60000]\n",
            "loss: 1304.702148  [ 9664/60000]\n",
            "loss: 833.826599  [10304/60000]\n",
            "loss: 971.817993  [10944/60000]\n",
            "loss: 1145.535889  [11584/60000]\n",
            "loss: 3221.967529  [12224/60000]\n",
            "loss: 1034.146851  [12864/60000]\n",
            "loss: 1414.088745  [13504/60000]\n",
            "loss: 413.403442  [14144/60000]\n",
            "loss: 1049.339600  [14784/60000]\n",
            "loss: 583.216187  [15424/60000]\n",
            "loss: 755.724976  [16064/60000]\n",
            "loss: 500.024963  [16704/60000]\n",
            "loss: 1317.164795  [17344/60000]\n",
            "loss: 1730.497681  [17984/60000]\n",
            "loss: 764.794250  [18624/60000]\n",
            "loss: 1686.631104  [19264/60000]\n",
            "loss: 1308.541504  [19904/60000]\n",
            "loss: 424.039246  [20544/60000]\n",
            "loss: 777.377686  [21184/60000]\n",
            "loss: 2264.898682  [21824/60000]\n",
            "loss: 696.509888  [22464/60000]\n",
            "loss: 589.770691  [23104/60000]\n",
            "loss: 726.378418  [23744/60000]\n",
            "loss: 1065.543945  [24384/60000]\n",
            "loss: 789.962891  [25024/60000]\n",
            "loss: 1230.254517  [25664/60000]\n",
            "loss: 1671.456543  [26304/60000]\n",
            "loss: 955.862244  [26944/60000]\n",
            "loss: 1089.136963  [27584/60000]\n",
            "loss: 521.666626  [28224/60000]\n",
            "loss: 480.740845  [28864/60000]\n",
            "loss: 1676.187378  [29504/60000]\n",
            "loss: 1666.691650  [30144/60000]\n",
            "loss: 790.776855  [30784/60000]\n",
            "loss: 230.957245  [31424/60000]\n",
            "loss: 456.105408  [32064/60000]\n",
            "loss: 720.853882  [32704/60000]\n",
            "loss: 749.903320  [33344/60000]\n",
            "loss: 1578.526855  [33984/60000]\n",
            "loss: 559.541016  [34624/60000]\n",
            "loss: 404.460266  [35264/60000]\n",
            "loss: 998.219666  [35904/60000]\n",
            "loss: 852.712158  [36544/60000]\n",
            "loss: 2313.510498  [37184/60000]\n",
            "loss: 752.977356  [37824/60000]\n",
            "loss: 1520.283936  [38464/60000]\n",
            "loss: 880.724487  [39104/60000]\n",
            "loss: 1178.264526  [39744/60000]\n",
            "loss: 1197.455566  [40384/60000]\n",
            "loss: 1307.630371  [41024/60000]\n",
            "loss: 927.012939  [41664/60000]\n",
            "loss: 1492.394775  [42304/60000]\n",
            "loss: 2465.514893  [42944/60000]\n",
            "loss: 1869.704590  [43584/60000]\n",
            "loss: 1673.927979  [44224/60000]\n",
            "loss: 978.162292  [44864/60000]\n",
            "loss: 900.586365  [45504/60000]\n",
            "loss: 715.215210  [46144/60000]\n",
            "loss: 1007.384216  [46784/60000]\n",
            "loss: 432.835938  [47424/60000]\n",
            "loss: 946.850403  [48064/60000]\n",
            "loss: 699.751160  [48704/60000]\n",
            "loss: 605.452637  [49344/60000]\n",
            "loss: 1306.148926  [49984/60000]\n",
            "loss: 495.467285  [50624/60000]\n",
            "loss: 1608.218750  [51264/60000]\n",
            "loss: 3447.270264  [51904/60000]\n",
            "loss: 2145.297363  [52544/60000]\n",
            "loss: 1031.029907  [53184/60000]\n",
            "loss: 444.139862  [53824/60000]\n",
            "loss: 828.442322  [54464/60000]\n",
            "loss: 1173.184204  [55104/60000]\n",
            "loss: 689.350708  [55744/60000]\n",
            "loss: 2086.277100  [56384/60000]\n",
            "loss: 1036.579956  [57024/60000]\n",
            "loss: 873.495850  [57664/60000]\n",
            "loss: 412.553528  [58304/60000]\n",
            "loss: 699.027893  [58944/60000]\n",
            "loss: 2795.963623  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 75.0%, Avg loss: 1358.935304 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 793.155762  [   64/60000]\n",
            "loss: 618.776855  [  704/60000]\n",
            "loss: 255.944336  [ 1344/60000]\n",
            "loss: 1158.038818  [ 1984/60000]\n",
            "loss: 1112.875122  [ 2624/60000]\n",
            "loss: 836.506165  [ 3264/60000]\n",
            "loss: 1200.612793  [ 3904/60000]\n",
            "loss: 655.518677  [ 4544/60000]\n",
            "loss: 2375.778564  [ 5184/60000]\n",
            "loss: 594.080261  [ 5824/60000]\n",
            "loss: 482.661072  [ 6464/60000]\n",
            "loss: 714.596375  [ 7104/60000]\n",
            "loss: 2661.798096  [ 7744/60000]\n",
            "loss: 1015.496277  [ 8384/60000]\n",
            "loss: 1783.157471  [ 9024/60000]\n",
            "loss: 2440.488770  [ 9664/60000]\n",
            "loss: 527.049194  [10304/60000]\n",
            "loss: 493.550354  [10944/60000]\n",
            "loss: 1120.470459  [11584/60000]\n",
            "loss: 2003.848633  [12224/60000]\n",
            "loss: 3142.137939  [12864/60000]\n",
            "loss: 1781.526855  [13504/60000]\n",
            "loss: 2387.040039  [14144/60000]\n",
            "loss: 1046.212158  [14784/60000]\n",
            "loss: 399.406311  [15424/60000]\n",
            "loss: 1434.912720  [16064/60000]\n",
            "loss: 1342.815063  [16704/60000]\n",
            "loss: 1221.130737  [17344/60000]\n",
            "loss: 1264.328857  [17984/60000]\n",
            "loss: 915.525879  [18624/60000]\n",
            "loss: 990.494385  [19264/60000]\n",
            "loss: 1132.969360  [19904/60000]\n",
            "loss: 452.920654  [20544/60000]\n",
            "loss: 1065.687866  [21184/60000]\n",
            "loss: 2133.140381  [21824/60000]\n",
            "loss: 726.690186  [22464/60000]\n",
            "loss: 657.439270  [23104/60000]\n",
            "loss: 866.405273  [23744/60000]\n",
            "loss: 920.002563  [24384/60000]\n",
            "loss: 711.514587  [25024/60000]\n",
            "loss: 1530.743408  [25664/60000]\n",
            "loss: 1617.606689  [26304/60000]\n",
            "loss: 1645.890869  [26944/60000]\n",
            "loss: 1803.038208  [27584/60000]\n",
            "loss: 502.461792  [28224/60000]\n",
            "loss: 369.906586  [28864/60000]\n",
            "loss: 1182.929199  [29504/60000]\n",
            "loss: 1335.689697  [30144/60000]\n",
            "loss: 532.189514  [30784/60000]\n",
            "loss: 385.397583  [31424/60000]\n",
            "loss: 980.102234  [32064/60000]\n",
            "loss: 887.455200  [32704/60000]\n",
            "loss: 758.248901  [33344/60000]\n",
            "loss: 955.737915  [33984/60000]\n",
            "loss: 416.140259  [34624/60000]\n",
            "loss: 841.237183  [35264/60000]\n",
            "loss: 880.786011  [35904/60000]\n",
            "loss: 1003.850281  [36544/60000]\n",
            "loss: 1822.587769  [37184/60000]\n",
            "loss: 435.043152  [37824/60000]\n",
            "loss: 1607.503540  [38464/60000]\n",
            "loss: 812.503723  [39104/60000]\n",
            "loss: 1016.444702  [39744/60000]\n",
            "loss: 883.904480  [40384/60000]\n",
            "loss: 1172.512817  [41024/60000]\n",
            "loss: 1080.780273  [41664/60000]\n",
            "loss: 1531.328125  [42304/60000]\n",
            "loss: 788.677368  [42944/60000]\n",
            "loss: 1972.682739  [43584/60000]\n",
            "loss: 1047.548584  [44224/60000]\n",
            "loss: 905.922424  [44864/60000]\n",
            "loss: 1010.469238  [45504/60000]\n",
            "loss: 675.531311  [46144/60000]\n",
            "loss: 888.426086  [46784/60000]\n",
            "loss: 632.583496  [47424/60000]\n",
            "loss: 1180.393555  [48064/60000]\n",
            "loss: 661.620850  [48704/60000]\n",
            "loss: 485.593567  [49344/60000]\n",
            "loss: 1833.543945  [49984/60000]\n",
            "loss: 859.696472  [50624/60000]\n",
            "loss: 2222.436523  [51264/60000]\n",
            "loss: 1116.417725  [51904/60000]\n",
            "loss: 1891.234863  [52544/60000]\n",
            "loss: 2055.221680  [53184/60000]\n",
            "loss: 985.000977  [53824/60000]\n",
            "loss: 706.142273  [54464/60000]\n",
            "loss: 567.046631  [55104/60000]\n",
            "loss: 680.254456  [55744/60000]\n",
            "loss: 411.096985  [56384/60000]\n",
            "loss: 1047.300171  [57024/60000]\n",
            "loss: 1465.459229  [57664/60000]\n",
            "loss: 286.705872  [58304/60000]\n",
            "loss: 755.988403  [58944/60000]\n",
            "loss: 2365.420410  [59584/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.8%, Avg loss: 2779.800081 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our model for later, so we can train more or make predictions\n",
        "\n",
        "EPOCH = epochs\n",
        "# We use the .pt file extension by convention for saving\n",
        "#    pytorch models\n",
        "PATH = \"model.pt\"\n",
        "\n",
        "# The save function creates a binary storing all our data for us\n",
        "torch.save({\n",
        "            'epoch': EPOCH,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            }, PATH)"
      ],
      "metadata": {
        "id": "Sb7p4C7poohU"
      },
      "id": "Sb7p4C7poohU",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify our path\n",
        "PATH = \"model.pt\"\n",
        "\n",
        "# Create a new \"blank\" model to load our information into\n",
        "model = FashionNet()\n",
        "\n",
        "# Recreate our optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Load back all of our data from the file\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "EPOCH = checkpoint['epoch']"
      ],
      "metadata": {
        "id": "OPtNFIqJp9Fi"
      },
      "id": "OPtNFIqJp9Fi",
      "execution_count": 29,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}